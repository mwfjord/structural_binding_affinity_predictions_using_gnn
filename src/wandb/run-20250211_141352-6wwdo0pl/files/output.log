Using GPU
Regenerating dataset...
Processing...
273it [01:25,  3.19it/s]
Done!
Regenerating dataset...
Processing...
38it [00:11,  3.24it/s]
Done!
Regenerating dataset...
Processing...
44it [00:13,  3.38it/s]
Done!
/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/proteinDNADataset.py:180: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(os.path.join(self.processed_dir,
2048
/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/train.py:105: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler()
Training:   0%|                                                                                                                                               | 0/18 [00:00<?, ?it/s]/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
This is the output:  tensor([[-0.1466],
        [-0.1465],
        [-0.1487],
        [-0.1501],
        [-0.1487],
        [-0.1494],
        [-0.1519],
        [-0.1466],
        [-0.1489],
        [-0.1467],
        [-0.1519],
        [-0.1508],
        [-0.1484],
        [-0.1489],
        [-0.1490],
        [-0.1487]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.5570,  9.5059,  4.5064,  9.7901,  2.8911,  5.7896, 10.8008,  9.4146,
         9.2412, 10.4900,  9.1332,  5.3436,  8.5321, 10.8008,  9.3904, 10.8008],
       device='cuda:0')
  return F.mse_loss(input, target, reduction=self.reduction)
/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
Training:   6%|███████▌                                                                                                                               | 1/18 [00:00<00:15,  1.10it/s]
This is the output:  tensor([[-0.1482],
        [-0.1515],
        [-0.1487],
        [-0.1466],
        [-0.1497],
        [-0.1487],
        [-0.1492],
        [-0.1494],
        [-0.1467],
        [-0.1508],
        [-0.1465],
        [-0.1489],
        [-0.1505],
        [-0.1467],
        [-0.1490],
        [-0.1501]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 3.7116,  3.4600,  4.3499,  3.7665,  9.3509, 10.8008, 10.1073,  4.9939,
         7.6216,  8.3428,  5.1310,  8.6835, 10.1548, 10.8008,  9.6851,  7.8635],
       device='cuda:0')
This is the output:  tensor([[-0.1512],
        [-0.1466],
        [-0.1501],
        [-0.1465],
        [-0.1494],
        [-0.1466],
        [-0.1519],
        [-0.1499],
        [-0.1505],
        [-0.1497],
        [-0.1519],
        [-0.1466],
        [-0.1467],
        [-0.1505],
        [-0.1499],
        [-0.1505]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.0459,  7.6878,  9.6701,  7.1150,  5.7579,  5.8236, 10.6173, 10.4156,
         8.7458,  2.0179,  9.8036, 10.8008,  9.3761,  6.4706, 10.8008,  5.1610],
       device='cuda:0')
This is the output:  tensor([[-0.1515],
        [-0.1464],
        [-0.1505],
        [-0.1467],
        [-0.1508],
        [-0.1499],
        [-0.1515],
        [-0.1489],
        [-0.1466],
        [-0.1515],
        [-0.1489],
        [-0.1519],
        [-0.1501],
        [-0.1465],
        [-0.1501],
        [-0.1499]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  7.9662,  7.8266, 10.8008,  7.3779,  8.7488,  3.1579, 10.8008,
         7.4624,  9.0434,  9.5670,  6.1585,  2.7386, 10.4450,  5.5699, 10.8008],
       device='cuda:0')
This is the output:  tensor([[-0.1499],
        [-0.1512],
        [-0.1512],
        [-0.1519],
        [-0.1505],
        [-0.1508],
        [-0.1466],
        [-0.1489],
        [-0.1501],
        [-0.1512],
        [-0.1509],
        [-0.1499],
        [-0.1508],
        [-0.1487],
        [-0.1497],
        [-0.1515]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.8561, 10.8008,  5.0042, 10.8008, 10.8008, 10.4347,  7.7130,  9.2983,
         8.1801,  9.5806,  3.0132,  9.5364, 10.8008, 10.8008,  9.5263, 10.8008],
       device='cuda:0')
This is the output:  tensor([[-0.1489],
        [-0.1499],
        [-0.1515],
        [-0.1501],
        [-0.1515],
        [-0.1499],
        [-0.1466],
        [-0.1505],
        [-0.1489],
        [-0.1465],
        [-0.1489],
        [-0.1501],
        [-0.1489],
        [-0.1497],
        [-0.1466],
        [-0.1467]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.8237,  8.8265,  7.2902,  6.0374,  7.0435, 10.8008,  9.8093,  8.9015,
        10.8008,  4.1592,  8.8291,  2.6868, 10.8008,  4.2921,  9.1644, 10.8008],
       device='cuda:0')
This is the output:  tensor([[-0.1223],
        [-0.1283],
        [-0.1219],
        [-0.1257],
        [-0.1216],
        [-0.1166],
        [-0.1216],
        [-0.1278],
        [-0.1250],
        [-0.1236],
        [-0.1229],
        [-0.1273],
        [-0.1270],
        [-0.1229],
        [-0.1278],
        [-0.1254]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.0165, 10.8008,  3.2356, 10.0811, 10.8008,  9.2336,  5.1598, 10.8008,
         4.0481,  9.7513,  8.6459,  8.3599, 10.8008,  9.7051,  4.9838, 10.2741],
       device='cuda:0')
This is the output:  tensor([[-0.0916],
        [-0.1015],
        [-0.0923],
        [-0.0842],
        [-0.0840],
        [-0.0975],
        [-0.0966],
        [-0.0840],
        [-0.0916],
        [-0.1015],
        [-0.1015],
        [-0.0975],
        [-0.1021],
        [-0.0950],
        [-0.0916],
        [-0.1003]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.7521,  6.3927, 10.8008,  8.5008,  5.3357, 10.8008,  5.3640,  4.8644,
         9.8510,  9.9640,  9.3087,  7.9825,  4.5797, 10.6732, 10.8008,  4.4720],
       device='cuda:0')
This is the output:  tensor([[-0.0742],
        [-0.0676],
        [-0.0591],
        [-0.0735],
        [-0.0742],
        [-0.0729],
        [-0.0483],
        [-0.0483],
        [-0.0638],
        [-0.0633],
        [-0.0587],
        [-0.0633],
        [-0.0633],
        [-0.0735],
        [-0.0591],
        [-0.0591]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3756,  7.3562,  8.0960, 10.8008,  9.4179,  8.6527,  3.4694,  9.1254,
        10.8008,  9.7631, 10.6434,  9.5587,  6.2477, 10.8008,  1.5437,  8.4658],
       device='cuda:0')
This is the output:  tensor([[-0.0431],
        [-0.0348],
        [-0.0230],
        [-0.0281],
        [-0.0235],
        [-0.0275],
        [-0.0341],
        [-0.0073],
        [-0.0230],
        [-0.0263],
        [-0.0275],
        [-0.0230],
        [-0.0080],
        [-0.0341],
        [-0.0080],
        [-0.0073]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.4405,  6.0799,  6.8974, 10.8008,  9.4764,  9.2624, 10.8008, 10.8008,
        10.8008,  5.0705, 10.8008,  9.6373, 10.8008,  6.1131,  9.3626, 10.0487],
       device='cuda:0')
This is the output:  tensor([[ 0.0374],
        [ 0.0184],
        [-0.0090],
        [ 0.0184],
        [ 0.0035],
        [-0.0082],
        [-0.0074],
        [ 0.0377],
        [ 0.0028],
        [ 0.0370],
        [ 0.0028],
        [ 0.0370],
        [ 0.0102],
        [ 0.0184],
        [-0.0066],
        [ 0.0374]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  6.0384,  8.4995,  6.0671,  4.3204,  2.6171,  8.6136,  8.3956,
         8.6955, 10.8008, 10.8008, 10.8008,  4.3061, 10.8008,  7.9487,  8.6913],
       device='cuda:0')
This is the output:  tensor([[0.0614],
        [0.0285],
        [0.0530],
        [0.0285],
        [0.0536],
        [0.0427],
        [0.0872],
        [0.0536],
        [0.0869],
        [0.0530],
        [0.0619],
        [0.0433],
        [0.0307],
        [0.0300],
        [0.0541],
        [0.0619]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.8165,  9.5656,  9.1819, 10.8008,  9.2554,  9.3229,  9.3783,  6.2979,
         9.5176, 10.6368,  8.8012, 10.8008,  8.4477, 10.8008,  6.0948,  4.5714],
       device='cuda:0')
This is the output:  tensor([[0.0710],
        [0.1416],
        [0.1411],
        [0.1414],
        [0.1005],
        [0.0883],
        [0.0696],
        [0.1005],
        [0.1414],
        [0.1106],
        [0.0690],
        [0.0878],
        [0.1097],
        [0.1110],
        [0.1110],
        [0.0866]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.4675, 10.8008, 10.8008,  7.3194,  7.4336,  2.5178,  9.0067, 10.0027,
         9.5651,  8.8457,  9.8850,  8.6061,  5.0916,  5.8157,  7.2419,  9.4764],
       device='cuda:0')
This is the output:  tensor([[0.2001],
        [0.1353],
        [0.1614],
        [0.1340],
        [0.1995],
        [0.1500],
        [0.1619],
        [0.1624],
        [0.1340],
        [0.1495],
        [0.1995],
        [0.1614],
        [0.1992],
        [0.1992],
        [0.1995],
        [0.1334]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.7301,  9.2675, 10.2597,  4.1199,  5.4878, 10.8008, 10.8008,  4.5833,
        10.8008,  1.6376, 10.0481, 10.8008,  6.1896, 10.3338,  9.0775, 10.7103],
       device='cuda:0')
This is the output:  tensor([[0.2598],
        [0.1586],
        [0.2598],
        [0.2600],
        [0.2012],
        [0.1577],
        [0.2012],
        [0.2006],
        [0.1836],
        [0.2012],
        [0.2605],
        [0.1586],
        [0.1577],
        [0.2018],
        [0.1836],
        [0.2600]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 3.7740,  3.8380,  9.1172,  9.4968, 10.0637, 10.8008,  8.6473,  5.3808,
         9.5294,  4.6239,  9.5890,  5.8400, 10.8008,  3.3253,  7.6966, 10.8008],
       device='cuda:0')
This is the output:  tensor([[0.2539],
        [0.2323],
        [0.2532],
        [0.2712],
        [0.3215],
        [0.2539],
        [0.3223],
        [0.2539],
        [0.3215],
        [0.2546],
        [0.2708],
        [0.3213],
        [0.2712],
        [0.2532],
        [0.2546],
        [0.2330]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  6.6234,  5.1883, 10.7407,  4.6932, 10.8008,  3.0530,  9.6113,
         9.4457,  6.4588,  6.4656,  5.2673,  7.5111,  9.2971,  9.2493,  9.3653],
       device='cuda:0')
This is the output:  tensor([[0.3291],
        [0.3291],
        [0.3860],
        [0.3276],
        [0.2544],
        [0.2544],
        [0.3870],
        [0.3857],
        [0.3857],
        [0.3298],
        [0.2532],
        [0.3096],
        [0.2556],
        [0.3291],
        [0.3867],
        [0.3867]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.3977,  4.7376,  9.3749,  5.0604,  9.1210, 10.8008,  3.2422,  4.5735,
        10.8008,  2.7156, 10.0182,  9.2869,  7.0692,  5.9598, 10.8008,  6.4486],
       device='cuda:0')
This is the output:  tensor([[0.3704]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([4.6065], device='cuda:0')
  return F.mse_loss(input, target, reduction=self.reduction)
Training:   0%|                                                                                                                                               | 0/18 [00:00<?, ?it/s]
This is the output:  tensor([[0.4583],
        [0.5293],
        [0.5288],
        [0.4583],
        [0.4565],
        [0.4573],
        [0.5293],
        [0.3596],
        [0.4014],
        [0.4565],
        [0.3643],
        [0.5293],
        [0.4326],
        [0.3596],
        [0.4348],
        [0.5298]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.0671,  7.6878, 10.8008,  5.8157,  8.8012,  2.8911,  9.4968, 10.6173,
         6.0799, 10.8008,  7.9487,  9.1254,  6.2979,  9.5656,  8.6459, 10.4450],
       device='cuda:0')
This is the output:  tensor([[0.6084],
        [0.5269],
        [0.6064],
        [0.6074],
        [0.6069],
        [0.6084],
        [0.6069],
        [0.6069],
        [0.4670],
        [0.5278],
        [0.4180],
        [0.5005],
        [0.5015],
        [0.4990],
        [0.5259],
        [0.6064]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.7301, 10.8008,  7.6216, 10.8008, 10.8008,  7.9662, 10.8008,  8.6913,
         8.6061,  2.7156,  4.5797,  6.4588,  9.7051,  9.6113,  6.4656, 10.8008],
       device='cuda:0')
This is the output:  tensor([[0.6890],
        [0.6895],
        [0.4792],
        [0.5996],
        [0.4844],
        [0.6899],
        [0.4792],
        [0.5332],
        [0.5693],
        [0.5996],
        [0.5308],
        [0.4810],
        [0.4829],
        [0.4810],
        [0.6895],
        [0.5986]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  5.3357,  9.8036,  8.4658,  8.4477,  9.2336,  6.1585,  4.3204,
         9.2554,  4.5064, 10.8008, 10.8008,  9.5806, 10.0182, 10.0487, 10.8008],
       device='cuda:0')
This is the output:  tensor([[0.7744],
        [0.6743],
        [0.5459],
        [0.5459],
        [0.5459],
        [0.6445],
        [0.5479],
        [0.7764],
        [0.6782],
        [0.6768],
        [0.6768],
        [0.7744],
        [0.6743],
        [0.6431],
        [0.6021],
        [0.6431]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.3904, 10.8008,  3.1579,  6.3927,  6.0948,  9.0459,  3.0530,
         6.0384, 10.8008,  8.0960, 10.8008, 10.8008, 10.8008,  4.1199,  4.2921],
       device='cuda:0')
This is the output:  tensor([[0.8667],
        [0.6782],
        [0.6782],
        [0.7568],
        [0.6782],
        [0.6147],
        [0.6763],
        [0.7583],
        [0.7202],
        [0.6147],
        [0.6187],
        [0.6763],
        [0.6147],
        [0.8652],
        [0.7568],
        [0.6128]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.5890,  4.0481,  7.6966, 10.8008,  8.1801,  3.4600,  8.9015,  8.3977,
         9.2971,  7.2902,  7.0692,  7.3562, 10.8008,  9.5176,  6.8974, 10.8008],
       device='cuda:0')
This is the output:  tensor([[0.9624],
        [0.7554],
        [0.9624],
        [0.6880],
        [0.8091],
        [0.8032],
        [0.8032],
        [0.8423],
        [0.9614],
        [0.6899],
        [0.7554],
        [0.9634],
        [0.8032],
        [0.8062],
        [0.7539],
        [0.9624]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3749,  7.9825,  7.3194,  9.3087,  5.0705,  8.7488,  5.3808,  5.0916,
         9.3626, 10.8008,  6.1131,  8.3956, 10.8008, 10.8008,  9.3229,  7.7130],
       device='cuda:0')
This is the output:  tensor([[1.0635],
        [0.8369],
        [0.9360],
        [0.8384],
        [0.9346],
        [1.0645],
        [0.9360],
        [0.8423],
        [1.0635],
        [0.8921],
        [0.7627],
        [0.8403],
        [0.9331],
        [0.9370],
        [0.7627],
        [0.8384]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.4347,  5.1598,  8.7458,  9.2412,  6.4486,  5.9598,  5.3640,
        10.4900,  1.6376, 10.8008,  2.7386, 10.0165, 10.6434, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[0.9282],
        [0.9858],
        [0.8486],
        [1.0303],
        [1.1699],
        [1.1699],
        [1.0283],
        [1.1699],
        [1.0303],
        [0.9858],
        [1.1699],
        [1.0312],
        [0.9844],
        [1.0303],
        [1.0303],
        [1.0283]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.5294,  4.9939, 10.8008,  8.6835,  9.3783, 10.8008,  9.6851,  8.5008,
        10.8008,  4.6065, 10.3338, 10.8008,  9.3509,  4.5714,  9.5670, 10.2597],
       device='cuda:0')
This is the output:  tensor([[1.0156],
        [1.1309],
        [1.2822],
        [1.2812],
        [1.0176],
        [1.0820],
        [1.2803],
        [1.2822],
        [1.1309],
        [1.2812],
        [1.0791],
        [0.9336],
        [0.9336],
        [1.0820],
        [1.2822],
        [1.2822]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.7103,  9.8510,  5.1310,  9.4146, 10.8008,  5.7579,  9.3761, 10.8008,
         4.5833,  3.7665, 10.8008,  8.6527,  5.0042,  3.3253, 10.8008,  7.1150],
       device='cuda:0')
This is the output:  tensor([[1.1143],
        [1.1143],
        [1.1836],
        [1.1143],
        [1.2393],
        [1.2373],
        [1.2354],
        [1.1182],
        [1.3994],
        [1.2354],
        [1.2373],
        [1.0234],
        [1.2373],
        [1.2393],
        [1.3994],
        [1.1826]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.4706, 10.1548,  7.4336,  7.8266, 10.8008, 10.8008, 10.8008,  2.5178,
        10.0481,  8.8291,  4.7376,  3.8380,  8.8457,  8.5321,  7.4624,  2.0179],
       device='cuda:0')
This is the output:  tensor([[1.3477],
        [1.2148],
        [1.2871],
        [1.5225],
        [1.5215],
        [1.2129],
        [1.3477],
        [1.1152],
        [1.2871],
        [1.1152],
        [1.1201],
        [1.1123],
        [1.2178],
        [1.1172],
        [1.5215],
        [1.2871]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 1.5437,  5.1610, 10.8008,  9.5651,  3.7740,  9.4764, 10.7407,  9.0434,
        10.6368,  2.6171,  4.4720,  9.4179,  7.8635,  8.6136,  6.1896, 10.4156],
       device='cuda:0')
This is the output:  tensor([[1.2188],
        [1.4014],
        [1.4639],
        [1.3252],
        [1.2158],
        [1.6494],
        [1.6494],
        [1.3994],
        [1.3232],
        [1.6514],
        [1.6494],
        [1.2100],
        [1.3975],
        [1.3184],
        [1.4619],
        [1.3184]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 3.0132,  9.2624,  4.3499,  9.5364,  9.1210,  9.1172,  5.2673,  9.7513,
         5.5699,  3.4694, 10.8008,  8.4995,  8.8265,  7.3779,  9.6373,  5.3436],
       device='cuda:0')
This is the output:  tensor([[1.5830],
        [1.3174],
        [1.4326],
        [1.3193],
        [1.5146],
        [1.4346],
        [1.5820],
        [1.7871],
        [1.5176],
        [1.4375],
        [1.3193],
        [1.5820],
        [1.5176],
        [1.5850],
        [1.3174],
        [1.7852]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.2983, 10.8008, 10.8008, 10.8008, 10.8008,  9.7901,  9.4764,  4.8644,
         6.2477,  9.2675,  5.8400,  5.0604, 10.8008,  7.5111, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[1.7139],
        [1.7100],
        [1.4307],
        [1.4248],
        [1.9277],
        [1.7100],
        [1.6387],
        [1.9268],
        [1.6387],
        [1.7148],
        [1.9277],
        [1.5488],
        [1.4219],
        [1.9268],
        [1.6416],
        [1.7080]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.2419,  3.2356, 10.8008,  9.9640,  9.5059, 10.8008,  9.5587,  7.5570,
         8.6473,  3.7116,  4.1592, 10.8008,  9.1332,  4.6932,  9.2493, 10.8008],
       device='cuda:0')
This is the output:  tensor([[1.6738],
        [1.8408],
        [2.0742],
        [1.6709],
        [2.0742],
        [2.0762],
        [1.5391],
        [1.7695],
        [1.7676],
        [1.6709],
        [1.6709],
        [1.5361],
        [2.0742],
        [1.6738],
        [1.7695],
        [1.8428]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.0374,  8.8165,  9.4457,  9.3653,  9.8093,  3.2422,  9.0067, 10.8008,
         9.5263,  8.6955, 10.8008, 10.8008,  5.8236,  2.6868, 10.0027,  9.8237],
       device='cuda:0')
This is the output:  tensor([[1.9014],
        [2.2285],
        [1.6572],
        [1.6572],
        [1.8994],
        [1.6572],
        [1.9062],
        [1.8994],
        [1.7988],
        [1.9014],
        [1.6543],
        [2.2285],
        [1.6543],
        [1.9014],
        [1.6641],
        [1.8994]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.7631,  4.5735,  7.0435, 10.8008, 10.6732, 10.8008, 10.1073,  9.1819,
        10.2741, 10.8008,  9.8850,  9.0775,  9.3756,  4.6239, 10.4675,  4.3061],
       device='cuda:0')
This is the output:  tensor([[1.9355],
        [2.0449],
        [1.9307],
        [2.0430],
        [2.1309],
        [1.7861],
        [1.9307],
        [1.7832],
        [2.0430],
        [2.3906],
        [1.9336],
        [2.0410],
        [2.0410],
        [1.9307],
        [2.1309],
        [2.3906]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.6701,  5.7896,  6.6234, 10.0637, 10.8008,  8.3599, 10.0811,  4.9838,
         9.2869,  5.4878, 10.8008,  9.8561,  5.1883,  8.3428, 10.7521,  9.1644],
       device='cuda:0')
This is the output:  tensor([[1.9092]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([4.4405], device='cuda:0')
This is the output:  tensor([[2.4414],
        [2.0508],
        [2.7344],
        [2.7363],
        [2.2227],
        [2.3398],
        [2.2148],
        [2.0469],
        [2.7363],
        [2.4414],
        [2.7324],
        [2.7344],
        [2.0566],
        [2.4395],
        [2.0469],
        [2.7324]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.7376, 10.8008,  9.5651,  8.3956,  2.7386,  9.8561,  7.3779,  9.5656,
         5.3357, 10.8008, 10.3338,  4.6932,  3.0132,  6.4656, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[2.3691],
        [2.6016],
        [2.6055],
        [2.6074],
        [2.3691],
        [2.6074],
        [2.9180],
        [2.1934],
        [2.9180],
        [2.5020],
        [2.6055],
        [2.1934],
        [2.5000],
        [2.6016],
        [2.3730],
        [2.3730]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.3904, 10.8008,  8.0960, 10.7103,  8.4658,  7.4624, 10.8008,
         8.6913,  4.6239,  8.8291,  9.0067, 10.4156,  9.6851,  5.1610, 10.1548],
       device='cuda:0')
This is the output:  tensor([[2.7852],
        [2.6719],
        [2.6680],
        [2.3516],
        [2.7773],
        [2.6719],
        [3.1133],
        [3.1113],
        [2.6719],
        [3.1113],
        [2.7852],
        [2.6758],
        [2.6758],
        [2.6680],
        [2.3398],
        [2.7852]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.8008, 10.6368,  4.4720, 10.2597, 10.0637,  4.1592,  9.3749,
         8.6473, 10.8008, 10.6434, 10.0027,  4.9939, 10.6732, 10.8008,  6.0671],
       device='cuda:0')
This is the output:  tensor([[2.7070],
        [3.3145],
        [2.9609],
        [2.9609],
        [2.5000],
        [2.9629],
        [3.3145],
        [2.8477],
        [2.8457],
        [2.5059],
        [2.4961],
        [3.3145],
        [2.6973],
        [2.7031],
        [2.5098],
        [2.9688]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.5699,  9.8093,  5.0916,  5.0604, 10.0182,  9.2983, 10.8008,  9.6113,
         5.3808,  8.3599,  4.4405,  9.1644,  9.3229,  8.6955,  7.9487,  6.0384],
       device='cuda:0')
This is the output:  tensor([[2.6660],
        [3.1543],
        [3.1582],
        [2.6660],
        [3.0332],
        [3.0371],
        [2.6699],
        [3.5273],
        [2.8770],
        [2.6699],
        [2.6738],
        [3.1602],
        [2.6660],
        [3.1582],
        [2.6660],
        [3.5293]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.2902, 10.8008,  4.3499,  6.3927,  1.6376,  6.0948,  8.6136,  8.5008,
         6.1131,  9.0459, 10.8008,  8.5321, 10.8008,  8.8457,  9.9640,  6.4486],
       device='cuda:0')
This is the output:  tensor([[3.2266],
        [3.0625],
        [3.2305],
        [3.0664],
        [3.7500],
        [3.7461],
        [2.8379],
        [3.7480],
        [2.8320],
        [3.3535],
        [3.7461],
        [3.7461],
        [3.7500],
        [3.3516],
        [3.0625],
        [3.7520]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.7513,  6.4706, 10.8008,  9.6701, 10.8008,  9.5176,  9.0434,  9.3783,
         9.8850,  9.5670,  9.3626, 10.8008,  5.1310, 10.8008,  9.3653,  7.9662],
       device='cuda:0')
This is the output:  tensor([[3.2227],
        [3.3574],
        [3.2227],
        [3.2305],
        [3.0664],
        [3.3535],
        [3.0625],
        [3.0664],
        [3.3535],
        [2.8379],
        [3.3535],
        [3.2305],
        [2.8320],
        [3.7500],
        [3.3574],
        [3.0566]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  4.5833,  4.3061,  7.4336,  7.6966,  3.2356, 10.2741,  2.6868,
         9.2412,  9.3087,  6.8974,  9.2493,  6.1585,  9.5890, 10.7407,  6.6234],
       device='cuda:0')
This is the output:  tensor([[3.0215],
        [3.5723],
        [3.9785],
        [3.9824],
        [3.2598],
        [3.5684],
        [3.0176],
        [3.2559],
        [3.0176],
        [3.2559],
        [3.9785],
        [3.2520],
        [3.9805],
        [3.4258],
        [3.4258],
        [3.2559]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.6527,  2.7156,  4.5735, 10.8008,  9.7901,  8.3977, 10.8008, 10.8008,
         4.9838, 10.8008,  6.1896,  6.0799,  9.4146,  9.2971,  8.8265,  4.1199],
       device='cuda:0')
This is the output:  tensor([[3.1992],
        [4.2227],
        [3.7832],
        [4.2227],
        [3.4512],
        [3.1992],
        [4.2227],
        [3.6445],
        [3.7793],
        [3.4648],
        [3.4570],
        [3.6406],
        [3.2051],
        [4.2227],
        [3.4570],
        [4.2227]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.5797,  7.6878, 10.8008,  9.3761, 10.0811,  9.3756,  3.4694,  6.4588,
         9.4764,  9.2675, 10.8008,  2.0179,  3.1579, 10.8008, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[4.4766],
        [3.4023],
        [3.4023],
        [4.0078],
        [3.8574],
        [4.4766],
        [4.4766],
        [3.6777],
        [4.4766],
        [4.0156],
        [4.4766],
        [3.6719],
        [3.8574],
        [4.0117],
        [3.8750],
        [3.4082]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.1172,  7.0435,  2.6171, 10.8008, 10.8008, 10.8008,  5.4878,  5.3640,
         9.4968,  2.8911,  5.8236,  4.0481,  8.7488,  8.8012,  5.0705,  9.1210],
       device='cuda:0')
This is the output:  tensor([[4.2578],
        [4.2539],
        [4.0938],
        [3.6016],
        [4.2578],
        [4.7422],
        [3.6016],
        [4.0898],
        [4.0938],
        [4.2500],
        [3.6074],
        [4.2578],
        [4.0938],
        [4.0898],
        [4.7422],
        [3.8945]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  8.6835,  9.3509, 10.6173, 10.8008,  5.2673, 10.8008,  9.1819,
        10.8008,  8.8165,  3.4600, 10.8008,  6.2477, 10.8008,  9.4457,  6.0374],
       device='cuda:0')
This is the output:  tensor([[5.0273],
        [4.3477],
        [4.5117],
        [4.1172],
        [4.3359],
        [4.1211],
        [4.1250],
        [4.5117],
        [3.8301],
        [4.1172],
        [4.3359],
        [5.0234],
        [4.3477],
        [5.0312],
        [4.3398],
        [5.0234]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 3.7665,  9.7051,  4.5064,  5.3436,  9.2869,  7.3562,  8.6061,  1.5437,
        10.8008, 10.4347,  9.7631, 10.8008,  8.6459,  3.0530,  5.7896, 10.4900],
       device='cuda:0')
This is the output:  tensor([[5.3203],
        [4.7695],
        [4.7773],
        [4.0664],
        [4.7734],
        [4.0469],
        [5.3242],
        [5.3281],
        [4.7812],
        [5.3203],
        [4.3672],
        [5.3242],
        [4.7734],
        [4.0586],
        [4.5938],
        [4.0469]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.5570, 10.0165,  7.5111, 10.4675,  9.6373,  8.4995, 10.4450,  9.2336,
         5.8157, 10.8008, 10.8008,  4.8644, 10.8008, 10.8008, 10.8008,  9.1332],
       device='cuda:0')
This is the output:  tensor([[4.2852],
        [4.3047],
        [4.8672],
        [4.8711],
        [4.2930],
        [4.6367],
        [4.8672],
        [4.6289],
        [5.0586],
        [4.8711],
        [5.0664],
        [4.6172],
        [5.6328],
        [5.6367],
        [5.0547],
        [4.3047]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.4179,  8.4477,  9.5587,  4.6065, 10.8008,  9.5364,  4.2921,  8.1801,
         5.9598,  5.7579,  7.2419,  8.3428,  7.6216, 10.0481, 10.8008,  7.0692],
       device='cuda:0')
This is the output:  tensor([[5.9688],
        [5.3555],
        [4.5508],
        [5.9648],
        [4.9023],
        [5.1484],
        [4.5430],
        [5.1562],
        [5.9727],
        [5.1641],
        [4.5352],
        [5.9688],
        [5.9648],
        [4.9062],
        [5.9648],
        [4.8906]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.1150,  5.1598, 10.8008,  9.0775,  4.3204,  5.1883, 10.8008,  9.2624,
         3.2422, 10.1073,  9.8036, 10.8008,  7.3194,  2.5178, 10.8008,  9.4764],
       device='cuda:0')
This is the output:  tensor([[5.6680],
        [4.8086],
        [5.4531],
        [5.1797],
        [5.4570],
        [5.6641],
        [5.1797],
        [5.6797],
        [4.8164],
        [5.4531],
        [4.8164],
        [4.8008],
        [5.1875],
        [5.6641],
        [6.3203],
        [5.4570]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.7521, 10.8008,  6.2979,  8.7458,  3.3253,  9.8237,  8.9015,  3.7116,
         9.5806,  9.2554,  5.8400, 10.8008,  9.5294,  4.5714,  8.7301, 10.8008],
       device='cuda:0')
This is the output:  tensor([[5.4883],
        [5.7656],
        [5.0938],
        [5.4805],
        [6.6758],
        [6.6758],
        [6.6758],
        [6.6758],
        [6.6797],
        [5.7617],
        [5.4805],
        [5.0938],
        [6.6797],
        [5.9961],
        [5.9961],
        [5.4805]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.8635,  9.5263,  3.8380,  7.9825,  7.7130,  9.1254,  3.7740, 10.8008,
         9.5059, 10.8008, 10.8008,  5.0042, 10.0487, 10.8008,  9.8510,  7.8266],
       device='cuda:0')
This is the output:  tensor([[6.3320]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008], device='cuda:0')
This is the output:  tensor([[5.6758],
        [5.6836],
        [6.1211],
        [7.4609],
        [6.1211],
        [6.1289],
        [7.4570],
        [6.6914],
        [5.6836],
        [7.4570],
        [6.1211],
        [6.4414],
        [5.6758],
        [6.1211],
        [6.7031],
        [7.4570]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.4179, 10.8008, 10.8008,  7.1150,  5.1610,  9.5294, 10.8008,  6.8974,
         9.9640,  8.5008, 10.8008,  4.2921,  8.4995, 10.2741, 10.8008,  9.1644],
       device='cuda:0')
This is the output:  tensor([[7.0703],
        [5.9922],
        [7.8750],
        [6.0039],
        [6.0117],
        [6.8008],
        [6.8008],
        [7.8750],
        [5.9922],
        [6.0117],
        [6.4805],
        [6.8086],
        [7.8711],
        [7.0820],
        [7.8750],
        [7.0781]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.0960,  6.1585,  7.4624, 10.8008, 10.8008,  9.7513,  9.2869,  9.5890,
        10.8008,  8.6136,  9.5364,  9.2493,  9.1172,  3.7116, 10.8008,  5.8157],
       device='cuda:0')
This is the output:  tensor([[8.3047],
        [7.4609],
        [7.4570],
        [6.8242],
        [6.3438],
        [8.3047],
        [7.1797],
        [6.3359],
        [7.4570],
        [8.3125],
        [8.3047],
        [7.1719],
        [6.3242],
        [6.3438],
        [7.4570],
        [7.1797]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.1254, 10.8008,  9.8237, 10.8008,  5.8400,  9.5651,  9.5587, 10.0182,
        10.8008,  9.5059,  9.4146,  8.7488,  9.8850,  3.8380,  8.6835,  4.6239],
       device='cuda:0')
This is the output:  tensor([[7.8711],
        [7.5664],
        [6.6875],
        [8.7578],
        [8.7578],
        [6.6875],
        [6.6953],
        [8.7578],
        [8.7656],
        [7.8711],
        [8.7656],
        [8.7656],
        [6.6953],
        [7.5820],
        [7.8633],
        [7.8594]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.4658, 10.8008,  9.3087,  6.1896,  5.4878,  7.0435,  9.1210,  9.3783,
         5.3357, 10.8008,  3.2422,  4.8644,  9.5806,  7.4336,  6.4656, 10.0165],
       device='cuda:0')
This is the output:  tensor([[7.5000],
        [6.9648],
        [7.9023],
        [7.5000],
        [7.5078],
        [7.8867],
        [8.1875],
        [6.9961],
        [9.1172],
        [7.5156],
        [9.1172],
        [7.5000],
        [8.2031],
        [7.8945],
        [8.2109],
        [6.9961]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.7103,  9.1332,  6.4588,  9.3229,  7.8266,  5.3808,  8.8165,  8.4477,
        10.8008,  4.0481, 10.3338, 10.8008, 10.8008,  6.2979,  2.7156,  3.0132],
       device='cuda:0')
This is the output:  tensor([[8.4688],
        [7.2188],
        [9.4062],
        [7.7656],
        [9.3984],
        [9.3984],
        [7.2188],
        [7.2188],
        [9.3984],
        [7.2383],
        [8.1406],
        [9.4062],
        [9.3984],
        [7.2070],
        [8.4609],
        [9.3984]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 2.8911, 10.8008,  9.2336,  2.7386,  3.4694,  4.6932,  4.9838,  6.3927,
         7.5570,  7.9487, 10.4156,  4.1592,  7.3194,  9.3756,  8.8012,  9.0775],
       device='cuda:0')
This is the output:  tensor([[9.6016],
        [8.3359],
        [9.5938],
        [9.5938],
        [8.6484],
        [7.4023],
        [7.3906],
        [8.3516],
        [9.5938],
        [7.4102],
        [8.6641],
        [8.3359],
        [7.4102],
        [8.6562],
        [7.9453],
        [7.9453]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.8561, 10.8008,  9.5176,  8.8291,  2.6171, 10.8008,  6.0948,
        10.8008, 10.8008,  6.0384,  8.8265,  8.6527,  8.3977,  8.7458,  8.9015],
       device='cuda:0')
This is the output:  tensor([[9.8281],
        [9.8281],
        [7.6133],
        [8.8672],
        [9.8359],
        [8.8750],
        [8.8750],
        [8.1562],
        [9.8281],
        [8.8750],
        [9.8281],
        [8.1562],
        [9.8281],
        [8.8672],
        [8.1797],
        [8.1719]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.0481, 10.8008,  7.2902, 10.8008,  6.4486,  7.5111,  5.1598, 10.1548,
         8.6913,  8.8457,  9.4968,  7.9825,  9.3761,  9.4764,  5.3640,  2.6868],
       device='cuda:0')
This is the output:  tensor([[8.3203],
        [7.7617],
        [7.7500],
        [8.7031],
        [9.0156],
        [7.7773],
        [8.7188],
        [9.9844],
        [8.7031],
        [7.7500],
        [8.7188],
        [9.0234],
        [9.0234],
        [9.9844],
        [9.0312],
        [8.7109]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.6701, 10.8008, 10.8008, 10.8008,  9.3904,  9.0459,  5.7896, 10.4450,
        10.6368,  9.5656,  5.7579, 10.8008, 10.8008, 10.8008,  1.5437, 10.8008],
       device='cuda:0')
This is the output:  tensor([[ 7.9336],
        [10.1719],
        [ 7.9453],
        [ 9.2266],
        [10.1719],
        [ 8.8984],
        [ 8.9062],
        [10.1719],
        [ 8.8984],
        [10.1797],
        [ 8.9062],
        [ 8.8984],
        [ 7.9570],
        [10.1719],
        [ 9.2109],
        [ 8.8984]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.4405,  9.8093,  3.4600,  8.5321,  7.6878,  2.0179,  9.2624,  5.2673,
         9.3509,  8.7301, 10.0027,  1.6376,  5.0042,  3.7665,  9.6373,  6.2477],
       device='cuda:0')
This is the output:  tensor([[ 9.3359],
        [ 9.3359],
        [10.2969],
        [ 8.0547],
        [10.2891],
        [ 9.0078],
        [ 8.6250],
        [ 8.6172],
        [ 9.0156],
        [ 8.6250],
        [10.2891],
        [ 9.0078],
        [10.2891],
        [ 9.0312],
        [ 8.6094],
        [ 9.3281]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.3499, 10.8008, 10.0487,  9.8036, 10.8008, 10.8008,  5.5699,  7.3562,
         9.6113,  8.1801,  7.7130,  4.3061, 10.8008,  8.6459,  7.3779,  9.5670],
       device='cuda:0')
This is the output:  tensor([[ 8.1406],
        [ 9.0781],
        [ 8.6875],
        [ 9.0938],
        [ 8.6875],
        [ 8.1641],
        [ 8.1328],
        [ 8.6797],
        [ 9.0781],
        [10.3438],
        [ 9.1016],
        [ 8.1562],
        [ 9.3984],
        [ 9.3906],
        [ 9.0859],
        [ 8.6875]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.1819, 10.8008,  3.3253,  8.6955,  7.0692,  4.5797,  5.3436,
         5.1883, 10.8008, 10.1073, 10.8008, 10.8008,  9.6851, 10.8008,  4.1199],
       device='cuda:0')
This is the output:  tensor([[ 9.4062],
        [ 9.3906],
        [ 9.0938],
        [ 8.6875],
        [ 8.7031],
        [10.3359],
        [ 9.4141],
        [ 9.3984],
        [ 8.7109],
        [10.3359],
        [10.3359],
        [ 8.7031],
        [10.3359],
        [ 9.3984],
        [ 9.0859],
        [ 8.7109]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.8510,  5.0916, 10.8008,  9.4764, 10.8008, 10.8008, 10.6434, 10.8008,
         9.7901, 10.4900,  5.8236,  6.4706,  9.3626,  3.2356, 10.8008,  8.6061],
       device='cuda:0')
This is the output:  tensor([[ 8.6719],
        [ 8.6953],
        [10.2812],
        [ 9.3750],
        [ 8.6797],
        [ 9.3594],
        [ 9.0547],
        [ 9.0547],
        [10.2891],
        [10.2734],
        [ 9.0625],
        [ 9.3594],
        [ 9.3672],
        [ 8.1328],
        [10.2891],
        [10.2891]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  2.5178,  9.3749,  7.2419,  4.3204, 10.8008,  9.7631,  8.6473,
         5.1310, 10.8008,  4.6065, 10.8008,  4.7376, 10.8008,  3.0530,  8.3956],
       device='cuda:0')
This is the output:  tensor([[ 8.6094],
        [ 8.9844],
        [ 8.1172],
        [10.1719],
        [ 8.9922],
        [ 8.9922],
        [ 9.2656],
        [ 9.2891],
        [ 8.6250],
        [ 9.2656],
        [ 8.9688],
        [10.1719],
        [ 8.5938],
        [10.1797],
        [ 9.0078],
        [ 8.6172]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3653, 10.0637, 10.8008,  7.6216,  4.9939, 10.8008,  5.0604,  6.0671,
         9.2675, 10.2597,  9.2971,  4.5735, 10.4347,  9.4457,  5.0705,  6.0374],
       device='cuda:0')
This is the output:  tensor([[8.4922],
        [8.0234],
        [8.8750],
        [8.0000],
        [9.1484],
        [9.1641],
        [8.4922],
        [9.1641],
        [9.1484],
        [9.1484],
        [8.0234],
        [8.8594],
        [9.1641],
        [8.4922],
        [8.0078],
        [7.9883]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.0811, 10.4675, 10.8008,  3.1579, 10.8008, 10.7407,  8.3428,  4.5833,
         4.5714,  9.2983,  4.4720, 10.6732,  5.9598,  6.6234,  8.3599, 10.6173],
       device='cuda:0')
This is the output:  tensor([[9.0000],
        [8.3750],
        [9.0078],
        [8.3672],
        [7.8789],
        [7.8789],
        [9.0078],
        [8.7266],
        [9.8516],
        [8.7266],
        [8.3594],
        [8.7422],
        [9.8594],
        [8.3750],
        [7.8789],
        [7.8789]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.2412,  7.6966, 10.7521,  6.1131,  9.0067, 10.8008,  4.5064,  9.5263,
        10.8008,  9.2554,  6.0799,  9.7051,  7.9662,  7.8635,  9.0434, 10.8008],
       device='cuda:0')
This is the output:  tensor([[9.7109]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([3.7740], device='cuda:0')
This is the output:  tensor([[9.7109],
        [8.6250],
        [9.7109],
        [8.6250],
        [8.8906],
        [8.8984],
        [8.2969],
        [9.7188],
        [8.9062],
        [8.9141],
        [9.7188],
        [8.9062],
        [7.8281],
        [8.9062],
        [9.7109],
        [8.8984]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.1172,  2.0179,  7.3194,  8.6473, 10.8008,  4.5064,  6.0374,  3.0530,
        10.6434,  3.7116,  4.8644,  6.0671, 10.8008,  5.8157,  9.3783, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.4922],
        [8.1797],
        [8.1875],
        [8.7578],
        [8.1562],
        [8.1797],
        [7.7188],
        [8.1641],
        [8.4922],
        [8.5000],
        [8.1797],
        [8.1875],
        [8.7578],
        [8.7500],
        [8.4844],
        [8.1797]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.7631,  8.1801,  9.5364, 10.8008,  7.3779,  4.0481,  3.4600,  7.3562,
         9.5587, 10.8008,  7.8635,  5.3640, 10.8008,  8.8012, 10.6368,  7.6966],
       device='cuda:0')
This is the output:  tensor([[7.6016],
        [8.3438],
        [8.5938],
        [8.5859],
        [8.5781],
        [8.5781],
        [7.6016],
        [8.5859],
        [7.6133],
        [7.6250],
        [7.5898],
        [9.3359],
        [9.3359],
        [9.3438],
        [7.6016],
        [8.0234]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  4.2921,  8.4658,  9.5670, 10.0165,  9.4764, 10.8008,  3.2356,
         5.8400,  3.0132, 10.6173,  6.1896,  9.5176, 10.4450,  7.2902,  6.0799],
       device='cuda:0')
This is the output:  tensor([[9.1172],
        [7.8789],
        [8.3906],
        [7.8672],
        [7.4609],
        [8.1562],
        [9.1094],
        [7.4492],
        [8.3984],
        [7.4609],
        [8.1562],
        [8.1797],
        [7.8672],
        [8.1719],
        [8.1719],
        [8.4062]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3749,  9.6701,  9.3904,  8.7458,  3.1579, 10.8008, 10.8008, 10.8008,
        10.8008, 10.8008, 10.4156, 10.1073, 10.8008,  7.4336,  5.7896,  4.5833],
       device='cuda:0')
This is the output:  tensor([[8.0703],
        [7.3867],
        [8.2812],
        [8.9688],
        [8.9609],
        [7.3750],
        [8.9688],
        [8.0547],
        [8.0547],
        [8.0547],
        [8.2812],
        [8.9609],
        [7.3750],
        [8.9688],
        [7.3633],
        [7.3867]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.7051,  8.3599, 10.7521,  6.4486, 10.8008,  9.3087,  5.3357,  9.7513,
         6.2979, 10.0637,  2.8911, 10.8008, 10.0182,  8.5008,  9.8850, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.8750],
        [7.3477],
        [8.2188],
        [7.9844],
        [7.3242],
        [7.9883],
        [8.8750],
        [7.9844],
        [8.8672],
        [7.3359],
        [7.3359],
        [7.9883],
        [7.3477],
        [7.7148],
        [7.3477],
        [7.9844]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.6932,  8.6136,  6.0384,  9.1819,  4.5797, 10.8008, 10.0487, 10.8008,
        10.8008, 10.8008,  4.9838,  6.2477,  3.8380, 10.8008,  9.5806,  5.3808],
       device='cuda:0')
This is the output:  tensor([[7.9414],
        [8.7656],
        [7.6797],
        [7.6875],
        [7.3125],
        [7.3125],
        [7.6719],
        [7.6797],
        [7.6602],
        [7.6797],
        [7.9336],
        [7.6797],
        [8.7734],
        [7.6719],
        [7.6602],
        [8.1406]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.6065, 10.8008,  4.3204,  9.2675,  6.3927,  9.9640, 10.2741,  2.7386,
         8.3428,  8.6061, 10.8008,  9.5294,  9.1644,  5.1610, 10.4347,  8.6835],
       device='cuda:0')
This is the output:  tensor([[7.3359],
        [8.7188],
        [8.7109],
        [8.7188],
        [8.7109],
        [7.6680],
        [8.7109],
        [7.3359],
        [7.3477],
        [7.6680],
        [7.6680],
        [8.1250],
        [8.1172],
        [7.6602],
        [7.3164],
        [8.7188]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.0042,  4.1592,  5.2673,  7.4624, 10.3338,  6.1131, 10.8008,  9.1210,
         7.0692,  8.9015,  9.3653,  4.3499, 10.8008,  5.3436,  8.4995, 10.8008],
       device='cuda:0')
This is the output:  tensor([[7.8789],
        [7.8594],
        [8.6250],
        [8.6328],
        [8.0469],
        [7.3320],
        [8.0547],
        [8.6328],
        [8.6250],
        [8.0625],
        [7.6328],
        [7.6250],
        [7.8594],
        [8.0469],
        [8.0547],
        [8.6328]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.2493,  4.3061,  9.4457,  7.9662, 10.2597, 10.8008, 10.8008,  8.7301,
         9.4146,  5.1598,  4.1199,  6.6234, 10.8008,  8.8165,  8.8291,  9.2336],
       device='cuda:0')
This is the output:  tensor([[8.0391],
        [7.8711],
        [7.8594],
        [8.5859],
        [7.3398],
        [7.3164],
        [8.5859],
        [7.8594],
        [8.0391],
        [7.3164],
        [8.0469],
        [8.5938],
        [7.3320],
        [7.8711],
        [7.3320],
        [8.5859]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.4656,  6.0948,  9.3509, 10.8008, 10.8008, 10.8008,  3.7665,  1.6376,
         6.8974,  9.4179,  8.8457,  9.5059,  2.6171,  5.7579, 10.8008,  3.7740],
       device='cuda:0')
This is the output:  tensor([[7.3359],
        [8.0078],
        [7.3047],
        [7.6094],
        [8.5078],
        [8.5156],
        [7.3359],
        [7.9961],
        [7.9883],
        [8.5078],
        [8.5078],
        [7.3047],
        [7.5977],
        [7.8125],
        [8.5078],
        [7.6094]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.4477, 10.8008,  4.4405,  7.8266,  9.1254, 10.8008, 10.4675,  7.5111,
        10.8008, 10.0481,  4.5735,  9.8036,  9.3229,  9.8561,  9.5651,  7.9825],
       device='cuda:0')
This is the output:  tensor([[7.8203],
        [7.8281],
        [7.6367],
        [7.3281],
        [7.8125],
        [7.9961],
        [7.8281],
        [7.6172],
        [7.9883],
        [7.3281],
        [7.3477],
        [7.3281],
        [8.4766],
        [8.4766],
        [7.3281],
        [8.4766]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.6239, 10.0027,  2.5178,  9.1332, 10.8008,  7.2419,  3.3253, 10.8008,
        10.8008,  9.3756,  8.6527,  9.5656,  7.7130, 10.8008,  6.1585,  9.8093],
       device='cuda:0')
This is the output:  tensor([[8.0234],
        [8.4844],
        [8.0234],
        [8.4922],
        [7.6523],
        [7.3828],
        [7.8594],
        [8.4922],
        [8.0156],
        [8.0078],
        [7.6523],
        [7.3945],
        [7.6641],
        [8.4922],
        [8.4922],
        [8.4844]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.7376, 10.4900,  8.5321,  7.1150, 10.0811, 10.8008,  9.2869,  8.6913,
         9.8237, 10.8008,  9.4764,  9.0067, 10.8008,  3.4694, 10.8008,  9.3761],
       device='cuda:0')
This is the output:  tensor([[7.7500],
        [8.0703],
        [8.0859],
        [8.0703],
        [8.0859],
        [8.5469],
        [8.0781],
        [8.5391],
        [8.5391],
        [7.9180],
        [8.5391],
        [7.9375],
        [7.4688],
        [7.9297],
        [8.5391],
        [7.7305]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 2.6868,  5.0604, 10.7407,  5.0916,  5.9598,  9.5890,  9.2412,  9.3626,
         7.6216,  9.2971,  9.4968,  6.4588, 10.8008, 10.8008,  7.6878, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.1797],
        [8.6172],
        [8.0312],
        [7.8438],
        [8.1719],
        [7.8438],
        [8.6172],
        [8.1641],
        [8.6172],
        [8.1797],
        [8.6250],
        [8.1797],
        [8.6172],
        [7.5977],
        [7.8555],
        [8.1719]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  8.3956,  4.9939, 10.8008,  9.6373,  8.6955,  5.1310,  9.6851,
         5.8236,  9.8510,  3.2422,  8.3977,  9.0775, 10.8008,  5.5699,  4.5714],
       device='cuda:0')
This is the output:  tensor([[8.0859],
        [7.6680],
        [7.8945],
        [8.0703],
        [8.6406],
        [8.2109],
        [7.9062],
        [8.0938],
        [8.2266],
        [8.2266],
        [7.9062],
        [8.0781],
        [7.9062],
        [7.6680],
        [7.6680],
        [8.0859]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  7.0435, 10.7103,  8.8265, 10.8008, 10.8008,  6.4706,  8.6459,
         8.0960,  1.5437, 10.8008,  9.6113, 10.1548,  9.0434, 10.8008,  9.2624],
       device='cuda:0')
This is the output:  tensor([[8.1641],
        [7.7969],
        [8.7031],
        [8.2969],
        [8.1875],
        [8.7109],
        [8.1562],
        [8.1562],
        [8.1562],
        [8.7031],
        [8.0078],
        [8.2969],
        [7.7969],
        [8.7031],
        [8.3125],
        [8.1641]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.2554,  7.9487,  5.4878,  9.2983,  5.0705, 10.8008,  8.7488, 10.6732,
         5.1883,  7.5570,  9.7901, 10.8008,  4.4720, 10.8008,  2.7156,  9.5263],
       device='cuda:0')
This is the output:  tensor([[7.8438]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([9.0459], device='cuda:0')
This is the output:  tensor([[8.7656],
        [8.7734],
        [8.7656],
        [8.1406],
        [8.2734],
        [8.3906],
        [8.2734],
        [7.9375],
        [8.3984],
        [7.9492],
        [8.1328],
        [8.3984],
        [8.3906],
        [8.3906],
        [7.9258],
        [8.1406]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3761,  5.8236,  6.1896,  5.5699,  9.1819, 10.2597,  4.3061, 10.8008,
        10.8008,  7.9487,  7.3562,  3.2356,  9.6851, 10.8008,  9.0067,  8.1801],
       device='cuda:0')
This is the output:  tensor([[8.4297],
        [8.3047],
        [8.1641],
        [8.2969],
        [8.7812],
        [7.9727],
        [7.9844],
        [8.4219],
        [8.4375],
        [8.4219],
        [8.4141],
        [7.9844],
        [8.7734],
        [8.3125],
        [8.1797],
        [8.7734]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 1.5437,  4.6239,  9.3653, 10.4156, 10.4450, 10.8008, 10.8008,  9.2412,
         7.2419,  4.5714,  5.0916,  8.3599,  7.6878,  9.2624,  8.6061,  9.3749],
       device='cuda:0')
This is the output:  tensor([[8.3203],
        [8.4141],
        [8.4297],
        [8.7500],
        [8.4062],
        [8.4297],
        [8.4219],
        [8.4219],
        [8.7578],
        [8.7656],
        [8.7578],
        [8.7578],
        [8.3125],
        [8.7500],
        [8.7578],
        [8.1562]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.1073, 10.8008, 10.8008,  4.5735, 10.0165,  5.8157, 10.7407,  4.5064,
        10.8008,  3.2422,  6.4486,  9.5651, 10.8008,  5.2673,  9.3783, 10.4347],
       device='cuda:0')
This is the output:  tensor([[7.9648],
        [7.9531],
        [8.2734],
        [8.1484],
        [8.7188],
        [8.4062],
        [8.2734],
        [8.7188],
        [7.9766],
        [8.2734],
        [8.7188],
        [8.7188],
        [8.3984],
        [7.9531],
        [8.2891],
        [8.3984]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.1332,  9.2971,  6.4706,  4.6932,  6.0671, 10.8008,  8.6913,
         9.0459,  5.1883, 10.8008, 10.4900, 10.8008,  9.8036,  6.0948,  8.0960],
       device='cuda:0')
This is the output:  tensor([[8.7031],
        [8.1484],
        [7.9727],
        [8.7031],
        [8.3906],
        [8.7109],
        [8.1406],
        [8.7188],
        [8.3828],
        [8.2812],
        [8.3828],
        [8.2891],
        [8.7109],
        [7.9961],
        [8.3906],
        [7.9961]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.8008,  7.0435, 10.8008,  9.8510,  7.1150,  6.6234,  7.9662,
         8.6835,  1.6376, 10.8008, 10.8008,  8.5008,  8.4477,  8.4658,  7.0692],
       device='cuda:0')
This is the output:  tensor([[8.1641],
        [8.1797],
        [8.4062],
        [7.9844],
        [7.9961],
        [7.9961],
        [7.9961],
        [8.7109],
        [8.1641],
        [8.0234],
        [8.2812],
        [8.1641],
        [8.3906],
        [8.2891],
        [7.9961],
        [8.2891]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.5294,  4.5833,  9.3756, 10.8008, 10.0182,  7.2902,  9.0775,
        10.8008,  3.0132,  9.8561, 10.8008, 10.8008,  6.2477, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.0469],
        [8.0312],
        [8.4297],
        [8.7266],
        [8.7266],
        [8.4297],
        [8.0312],
        [8.3281],
        [8.0312],
        [8.4297],
        [8.3125],
        [8.3281],
        [8.7266],
        [8.4219],
        [8.4219],
        [8.0234]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.9640,  2.8911,  9.5176,  7.6216, 10.8008,  6.3927,  9.3509,
         9.0434,  4.3499, 10.8008,  9.6113, 10.8008,  8.8012,  9.2983,  9.4179],
       device='cuda:0')
This is the output:  tensor([[8.4766],
        [8.3672],
        [8.7656],
        [8.0859],
        [8.4688],
        [8.2500],
        [8.2578],
        [8.2656],
        [8.2500],
        [8.4844],
        [8.7656],
        [8.7656],
        [8.3672],
        [8.1016],
        [8.2578],
        [8.7734]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.7376,  8.6473,  9.4146, 10.8008, 10.8008, 10.1548,  2.6868,  9.5364,
        10.8008,  2.7156,  9.1254,  7.3194,  9.5263,  8.6527,  6.0374, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.3984],
        [8.2734],
        [8.5078],
        [8.3984],
        [8.5078],
        [8.1250],
        [8.3984],
        [8.7812],
        [8.3828],
        [8.2891],
        [8.7812],
        [8.7891],
        [8.1406],
        [8.1172],
        [8.3906],
        [8.5000]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.7896,  8.9015,  6.0384, 10.0027,  3.7116,  5.0042,  4.6065,  5.4878,
        10.6732,  2.7386, 10.8008,  9.5059, 10.4675, 10.8008,  6.2979, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.4844],
        [8.5000],
        [8.3984],
        [8.5078],
        [8.2812],
        [8.4062],
        [8.1484],
        [8.5000],
        [8.2734],
        [8.7812],
        [8.7812],
        [8.3906],
        [8.7734],
        [8.7734],
        [8.1172],
        [8.7812]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3904, 10.8008,  2.0179,  8.5321,  8.7458,  7.4336, 10.8008,  5.9598,
         7.3779,  8.7301,  3.0530,  8.7488,  3.7740,  3.7665, 10.8008,  4.8644],
       device='cuda:0')
This is the output:  tensor([[8.4688],
        [8.3750],
        [8.1250],
        [8.1250],
        [8.4688],
        [8.2969],
        [8.3906],
        [8.4688],
        [8.2969],
        [8.1094],
        [8.7500],
        [8.7500],
        [8.3906],
        [8.2812],
        [8.2656],
        [8.1328]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.8165, 10.6368,  2.6171,  9.3087,  5.0604,  2.5178,  4.9939,  9.4764,
         9.2675,  6.1585,  9.4968,  9.1644,  3.3253,  4.3204, 10.0811,  9.1210],
       device='cuda:0')
This is the output:  tensor([[8.0859],
        [8.0859],
        [8.7109],
        [8.7188],
        [8.2344],
        [8.3438],
        [8.2578],
        [8.7109],
        [8.1094],
        [8.2422],
        [8.4453],
        [8.7188],
        [8.3828],
        [8.1094],
        [8.3516],
        [8.4453]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.5656,  9.8850,  9.4457, 10.0487,  6.0799, 10.8008,  4.0481,  3.4694,
         8.6136, 10.8008,  9.6373, 10.8008,  5.0705,  9.5806, 10.8008,  6.8974],
       device='cuda:0')
This is the output:  tensor([[8.4375],
        [8.4297],
        [8.2500],
        [8.4375],
        [8.0859],
        [8.6953],
        [8.0859],
        [8.0859],
        [8.6875],
        [8.3438],
        [8.2500],
        [8.2578],
        [8.2266],
        [8.4297],
        [8.1094],
        [8.3516]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.1598,  9.8237,  9.7901, 10.8008, 10.8008,  7.4624,  4.4405, 10.8008,
        10.8008, 10.0637,  9.6701,  5.3640,  9.3229, 10.8008,  5.8400,  9.2493],
       device='cuda:0')
This is the output:  tensor([[8.2656],
        [8.3672],
        [8.6953],
        [8.1016],
        [8.6875],
        [8.7031],
        [8.6875],
        [8.2500],
        [8.3516],
        [8.1016],
        [8.7031],
        [8.3438],
        [8.1094],
        [8.2500],
        [8.1250],
        [8.7031]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.8635,  8.6459, 10.0481, 10.6173,  9.1172,  9.5890, 10.8008, 10.2741,
         9.5587,  4.5797,  9.2336, 10.8008, 10.8008,  4.1199,  3.8380,  8.3956],
       device='cuda:0')
This is the output:  tensor([[8.3672],
        [8.2656],
        [8.7031],
        [8.4688],
        [8.7031],
        [8.2656],
        [8.3672],
        [8.3906],
        [8.4531],
        [8.2656],
        [8.7109],
        [8.1406],
        [8.1406],
        [8.1641],
        [8.7109],
        [8.7109]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.8265, 10.7103, 10.3338,  7.5111,  9.3626,  9.4764,  5.3808,  9.7051,
         6.4656,  8.3428, 10.8008,  3.1579,  4.9838,  4.4720,  5.1310,  4.1592],
       device='cuda:0')
This is the output:  tensor([[8.7031],
        [8.2812],
        [8.1484],
        [8.4609],
        [8.2812],
        [8.1328],
        [8.2812],
        [8.2891],
        [8.3750],
        [8.4609],
        [8.2734],
        [8.3750],
        [8.4766],
        [8.4609],
        [8.2812],
        [8.3750]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  5.1610,  3.4600,  9.5670,  7.9825,  8.4995,  7.8266,  7.6966,
         9.2869, 10.8008,  5.3436,  9.7631, 10.6434,  8.8291,  6.1131,  4.2921],
       device='cuda:0')
This is the output:  tensor([[8.3672],
        [8.4531],
        [8.1328],
        [8.3750],
        [8.2578],
        [8.3672],
        [8.6953],
        [8.6875],
        [8.2734],
        [8.3750],
        [8.4531],
        [8.6875],
        [8.6875],
        [8.6875],
        [8.4531],
        [8.6875]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.7521, 10.8008,  6.4588, 10.8008,  9.2554,  5.3357, 10.8008,
         8.6955,  5.7579,  8.8457, 10.8008,  7.5570,  7.7130,  8.3977,  9.8093],
       device='cuda:0')
This is the output:  tensor([[8.3750]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([9.7513], device='cuda:0')
This is the output:  tensor([[8.1719],
        [8.2969],
        [8.2891],
        [8.4609],
        [8.7031],
        [8.1875],
        [8.3203],
        [8.3828],
        [8.3203],
        [8.6953],
        [8.4844],
        [8.4609],
        [8.2969],
        [8.7031],
        [8.1953],
        [8.1719]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3087,  9.3653,  5.3436, 10.8008,  9.3749,  8.6527,  9.2675, 10.4156,
         2.5178, 10.4900,  7.2419,  9.6851, 10.8008,  7.1150,  8.4477, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.5078],
        [8.1953],
        [8.3438],
        [8.3281],
        [8.5078],
        [8.7266],
        [8.3281],
        [8.2266],
        [8.4297],
        [8.7266],
        [8.5078],
        [8.7266],
        [8.7422],
        [8.5000],
        [8.1953],
        [8.7266]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.4658, 10.8008,  7.8635,  8.9015,  9.8510,  9.1644, 10.2741,  7.0692,
        10.8008,  7.5570, 10.8008,  9.1254,  8.7301,  9.2412,  9.5656, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.7656],
        [8.7656],
        [8.7656],
        [8.4688],
        [8.3672],
        [8.5469],
        [8.4531],
        [8.3828],
        [8.2344],
        [8.3594],
        [8.5312],
        [8.3594],
        [8.5469],
        [8.4531],
        [8.4766],
        [8.5391]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.4624,  5.4878,  7.6216,  7.4336, 10.8008,  7.5111, 10.6732,  9.5294,
         9.3756,  7.3779, 10.2597, 10.4347, 10.8008,  8.7488, 10.1073, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.6016],
        [8.2969],
        [8.8125],
        [8.5859],
        [8.8203],
        [8.4297],
        [8.5156],
        [8.3047],
        [8.5859],
        [8.5078],
        [8.8125],
        [8.5078],
        [8.4062],
        [8.2969],
        [8.5234],
        [8.4297]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.8157, 10.8008,  3.7665, 10.8008,  3.0530,  2.6868,  5.7896,  9.5806,
         8.8012,  4.6239, 10.8008, 10.0637, 10.8008,  9.0434,  8.6459,  5.5699],
       device='cuda:0')
This is the output:  tensor([[8.8438],
        [8.5234],
        [8.3359],
        [8.4453],
        [8.3281],
        [8.3281],
        [8.4453],
        [8.8438],
        [8.3125],
        [8.8438],
        [8.6172],
        [8.4453],
        [8.8359],
        [8.8359],
        [8.5234],
        [8.5391]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.8093,  5.3808,  9.1210,  8.7458, 10.8008, 10.8008,  5.1610,  9.0775,
        10.6173,  9.4457,  8.8457,  7.3562,  5.2673, 10.8008, 10.8008,  9.2869],
       device='cuda:0')
This is the output:  tensor([[8.6484],
        [8.8750],
        [8.3594],
        [8.3594],
        [8.3516],
        [8.6406],
        [8.3594],
        [8.8750],
        [8.5703],
        [8.3906],
        [8.5625],
        [8.4766],
        [8.5625],
        [8.5703],
        [8.6562],
        [8.3594]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.4146,  7.0435,  6.3927,  9.8850,  5.0604,  9.9640, 10.8008,
         1.6376,  7.9487, 10.8008,  9.4764, 10.6368, 10.8008,  4.5833, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.4141],
        [8.8906],
        [8.3750],
        [8.5156],
        [8.6016],
        [8.5156],
        [8.8984],
        [8.3906],
        [8.6797],
        [8.3984],
        [8.6719],
        [8.3750],
        [8.5938],
        [8.8984],
        [8.5938],
        [8.3906]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 3.0132, 10.8008,  6.1585,  9.6701, 10.0027,  8.6061,  4.6932,  3.4600,
        10.7407,  8.3599, 10.8008,  9.8036, 10.8008,  8.5008,  9.5587,  4.9838],
       device='cuda:0')
This is the output:  tensor([[8.5156],
        [8.6016],
        [8.8906],
        [8.6094],
        [8.5078],
        [8.6953],
        [8.5391],
        [8.8984],
        [8.4141],
        [8.6250],
        [8.8984],
        [8.5234],
        [8.3984],
        [8.5156],
        [8.8984],
        [8.6797]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  8.6473, 10.8008,  9.2624, 10.7103,  8.5321,  5.3640,  9.5651,
         5.8400,  5.0705,  9.5059,  4.0481, 10.0182,  6.4706,  8.3956,  4.7376],
       device='cuda:0')
This is the output:  tensor([[8.3984],
        [8.5156],
        [8.6797],
        [8.4062],
        [8.3828],
        [8.8828],
        [8.6719],
        [8.8906],
        [8.3984],
        [8.4062],
        [8.6641],
        [8.3828],
        [8.6797],
        [8.6797],
        [8.8906],
        [8.5859]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 2.6171,  6.1131, 10.7521, 10.8008, 10.8008,  9.3626,  6.4656, 10.8008,
         9.0067,  8.6136, 10.8008,  9.4179, 10.8008, 10.8008, 10.8008,  4.3061],
       device='cuda:0')
This is the output:  tensor([[8.6016],
        [8.8984],
        [8.5234],
        [8.6016],
        [8.8984],
        [8.5234],
        [8.3906],
        [8.4297],
        [8.5078],
        [8.5938],
        [8.4062],
        [8.6797],
        [8.8906],
        [8.4062],
        [8.6016],
        [8.8984]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.2921, 10.8008,  8.6955, 10.8008,  5.1310,  7.9825, 10.8008,  4.4720,
         6.6234,  8.8265, 10.8008,  5.1598,  7.7130,  7.2902,  9.2554, 10.4450],
       device='cuda:0')
This is the output:  tensor([[8.5078],
        [8.6641],
        [8.4141],
        [8.8828],
        [8.8750],
        [8.6719],
        [8.4062],
        [8.5156],
        [8.5078],
        [8.8906],
        [8.6094],
        [8.5859],
        [8.5234],
        [8.6016],
        [8.8750],
        [8.5156]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.3428,  8.8165,  5.0042,  7.3194,  3.7740,  9.8237, 10.8008, 10.8008,
        10.0811,  3.2422,  4.6065,  9.1819,  8.1801,  9.6113, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.8594],
        [8.5859],
        [8.6797],
        [8.8594],
        [8.5938],
        [8.8594],
        [8.8672],
        [8.5156],
        [8.4062],
        [8.5938],
        [8.8750],
        [8.6641],
        [8.5859],
        [8.6484],
        [8.8594],
        [8.5781]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  6.2979,  3.7116,  8.6913,  6.4588, 10.0481,  4.1592,  9.7901,
         3.8380, 10.8008,  7.9662,  8.0960,  9.5263,  9.3904,  9.3783,  5.1883],
       device='cuda:0')
This is the output:  tensor([[8.6250],
        [8.4688],
        [8.5703],
        [8.6406],
        [8.8281],
        [8.8281],
        [8.6250],
        [8.6250],
        [8.3984],
        [8.4922],
        [8.5781],
        [8.5547],
        [8.8281],
        [8.4922],
        [8.8359],
        [8.6328]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.5714,  6.0799,  4.9939,  6.0384,  6.1896, 10.3338,  8.8291,  8.6835,
        10.8008,  7.6966,  9.7051,  2.0179,  4.5735,  6.0374,  3.4694,  2.8911],
       device='cuda:0')
This is the output:  tensor([[8.3359],
        [8.8047],
        [8.5234],
        [8.8047],
        [8.3359],
        [8.8047],
        [8.7969],
        [8.6094],
        [8.3359],
        [8.7969],
        [8.5938],
        [8.5391],
        [8.4766],
        [8.5938],
        [8.8125],
        [8.6094]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.1332,  6.4486,  9.2971, 10.0487,  4.5797,  4.8644,  9.5176,  1.5437,
        10.8008, 10.8008, 10.8008,  6.0948,  9.5364, 10.8008,  9.2336, 10.6434],
       device='cuda:0')
This is the output:  tensor([[8.5781],
        [8.5625],
        [8.4844],
        [8.5078],
        [8.4297],
        [8.3359],
        [8.5547],
        [8.7656],
        [8.4141],
        [8.4922],
        [8.7578],
        [8.7578],
        [8.4141],
        [8.5625],
        [8.5781],
        [8.4141]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.0671,  6.8974, 10.8008,  5.7579,  2.7386, 10.4675, 10.0165,  9.5890,
        10.1548,  6.2477,  9.1172,  9.3761,  7.8266,  3.2356,  2.7156,  4.1199],
       device='cuda:0')
This is the output:  tensor([[8.7109],
        [8.4531],
        [8.2891],
        [8.5078],
        [8.3750],
        [8.5156],
        [8.5312],
        [8.7109],
        [8.4609],
        [8.4531],
        [8.2891],
        [8.5156],
        [8.4531],
        [8.5234],
        [8.5234],
        [8.3906]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.4968,  9.7513, 10.8008,  9.4764, 10.8008,  9.6373, 10.8008, 10.8008,
         9.2493,  9.7631,  9.0459,  9.2983,  9.3509,  4.5064, 10.8008,  4.3204],
       device='cuda:0')
This is the output:  tensor([[8.4844],
        [8.6797],
        [8.4219],
        [8.4219],
        [8.5000],
        [8.5000],
        [8.6797],
        [8.2422],
        [8.5000],
        [8.2500],
        [8.2422],
        [8.6797],
        [8.6875],
        [8.4375],
        [8.4922],
        [8.3438]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.0916,  7.6878,  9.8561, 10.8008,  4.3499,  5.9598, 10.8008,  4.4405,
         8.3977,  3.1579,  8.4995,  5.8236,  5.3357,  3.3253,  9.5670,  9.3229],
       device='cuda:0')
This is the output:  tensor([[8.2344]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008], device='cuda:0')
This is the output:  tensor([[8.3672],
        [8.3047],
        [8.4531],
        [8.2109],
        [8.3672],
        [8.6172],
        [8.3906],
        [8.4375],
        [8.3750],
        [8.2969],
        [8.2188],
        [8.4531],
        [8.2188],
        [8.3203],
        [8.4375],
        [8.6328]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.3061,  8.7458, 10.8008,  3.1579, 10.8008, 10.8008,  3.3253,  9.2983,
         9.2554,  8.3428,  8.3599,  8.5321, 10.8008,  4.3204, 10.8008,  9.5890],
       device='cuda:0')
This is the output:  tensor([[8.3516],
        [8.4219],
        [8.3594],
        [8.3750],
        [8.1719],
        [8.5938],
        [8.6016],
        [8.1719],
        [8.5938],
        [8.5938],
        [8.3438],
        [8.3672],
        [8.4219],
        [8.3516],
        [8.1953],
        [8.2969]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3509,  5.9598, 10.8008,  5.0705,  9.8036,  9.3761, 10.8008,  9.4179,
        10.8008, 10.0481,  5.1883, 10.1073, 10.8008,  6.2477,  9.1210,  9.6701],
       device='cuda:0')
This is the output:  tensor([[8.3906],
        [8.2578],
        [8.1719],
        [8.1953],
        [8.1719],
        [8.5781],
        [8.5859],
        [8.2812],
        [8.3281],
        [8.3359],
        [8.1719],
        [8.5859],
        [8.5781],
        [8.5703],
        [8.3281],
        [8.3281]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.2597,  9.3229,  7.2902,  7.0692, 10.8008,  9.5651,  7.9662,  2.7386,
         8.8265,  1.6376,  9.0067,  4.1592,  9.4146,  9.1172,  5.3808,  8.7488],
       device='cuda:0')
This is the output:  tensor([[8.3984],
        [8.5625],
        [8.1797],
        [8.2578],
        [8.2422],
        [8.1484],
        [8.3281],
        [8.3984],
        [8.2500],
        [8.3828],
        [8.1484],
        [8.1562],
        [8.2734],
        [8.1562],
        [8.1719],
        [8.2578]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.8157, 10.8008, 10.4675,  8.6061,  6.0799,  4.5797,  9.2624,  2.7156,
        10.8008, 10.8008,  9.1332, 10.8008,  2.5178,  6.3927,  5.0042,  2.6868],
       device='cuda:0')
This is the output:  tensor([[8.1328],
        [8.2969],
        [8.5234],
        [8.2969],
        [8.5312],
        [8.1562],
        [8.3516],
        [8.5312],
        [8.2969],
        [8.2344],
        [8.3672],
        [8.2500],
        [8.5234],
        [8.3594],
        [8.1562],
        [8.5312]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 2.6171,  9.2869, 10.8008,  9.6113, 10.8008,  3.0132,  3.2356, 10.4450,
         4.2921,  4.0481,  6.0384,  9.2675,  9.5176,  8.3977, 10.8008,  5.4878],
       device='cuda:0')
This is the output:  tensor([[8.3281],
        [8.3359],
        [8.3281],
        [8.2031],
        [8.3281],
        [8.3359],
        [8.5000],
        [8.3281],
        [8.2578],
        [8.3203],
        [8.5000],
        [8.5000],
        [8.2031],
        [8.2031],
        [8.2109],
        [8.5078]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.7521,  9.8237,  8.6955,  8.8291,  7.5111,  9.4968, 10.8008,
        10.4156,  5.0916,  5.8236,  7.7130,  5.1610,  8.9015,  8.1801,  8.7301],
       device='cuda:0')
This is the output:  tensor([[8.3047],
        [8.1875],
        [8.2422],
        [8.3125],
        [8.1953],
        [8.0938],
        [8.4766],
        [8.2422],
        [8.1172],
        [8.2578],
        [8.4766],
        [8.3125],
        [8.3203],
        [8.4766],
        [8.4844],
        [8.2578]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.2412,  6.1131, 10.8008,  4.5833,  5.5699, 10.8008,  7.4624,  9.1819,
         8.4477,  5.7579, 10.3338,  8.0960,  6.0671,  4.6932,  7.1150,  6.4588],
       device='cuda:0')
This is the output:  tensor([[8.4609],
        [8.4688],
        [8.4531],
        [8.0859],
        [8.2891],
        [8.1641],
        [8.4609],
        [8.4531],
        [8.0781],
        [8.2812],
        [8.1641],
        [8.4609],
        [8.2500],
        [8.0781],
        [8.1719],
        [8.2422]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.3357,  3.2422, 10.8008, 10.8008,  8.6835,  7.3562,  8.3956, 10.8008,
         4.9838, 10.8008,  7.8266,  9.4457,  9.7051, 10.8008,  9.5294, 10.0027],
       device='cuda:0')
This is the output:  tensor([[8.4531],
        [8.4375],
        [8.2266],
        [8.2734],
        [8.4453],
        [8.4453],
        [8.0547],
        [8.0781],
        [8.1641],
        [8.1406],
        [8.1719],
        [8.2188],
        [8.4453],
        [8.2109],
        [8.0781],
        [8.2734]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 3.0530,  3.7740,  9.2493,  6.8974,  7.3194,  8.6913,  4.4405,  8.6527,
         7.8635,  6.6234,  5.3640, 10.8008,  7.6878, 10.8008,  3.8380,  9.5670],
       device='cuda:0')
This is the output:  tensor([[8.4219],
        [8.0469],
        [8.2500],
        [8.2578],
        [8.4297],
        [8.2578],
        [8.4219],
        [8.2109],
        [8.2734],
        [8.2031],
        [8.0469],
        [8.2656],
        [8.1250],
        [8.1562],
        [8.1484],
        [8.1484]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.1896, 10.8008,  9.4764,  4.5714,  9.2336,  9.6373,  9.0775, 10.8008,
         7.2419,  9.7631,  7.0435,  4.7376, 10.7103,  9.5364,  9.7901,  7.6966],
       device='cuda:0')
This is the output:  tensor([[8.4219],
        [8.2422],
        [8.1250],
        [8.4219],
        [8.0391],
        [8.2578],
        [8.4141],
        [8.2578],
        [8.4141],
        [8.2656],
        [8.4141],
        [8.2031],
        [8.2031],
        [8.0312],
        [8.2578],
        [8.0391]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.8644, 10.8008, 10.8008, 10.0487,  9.3087, 10.7407,  9.8093,  8.4658,
         9.1644,  3.7116,  8.5008,  5.7896,  4.6065, 10.6173, 10.8008,  3.4600],
       device='cuda:0')
This is the output:  tensor([[8.1094],
        [8.2422],
        [8.1172],
        [8.1172],
        [8.0234],
        [8.1797],
        [8.2422],
        [8.3984],
        [8.0312],
        [8.0234],
        [8.4062],
        [8.1953],
        [8.1172],
        [8.4062],
        [8.2422],
        [8.1797]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.3436, 10.8008,  4.1199, 10.8008,  8.4995,  2.0179, 10.8008, 10.4900,
        10.8008,  9.5656, 10.8008,  8.6459, 10.8008,  9.5059,  1.5437,  9.5263],
       device='cuda:0')
This is the output:  tensor([[8.0391],
        [8.1719],
        [8.3906],
        [8.2344],
        [8.0156],
        [8.0391],
        [8.1016],
        [8.1094],
        [8.3906],
        [8.1172],
        [8.0234],
        [8.2344],
        [8.1797],
        [8.0234],
        [8.3906],
        [8.1094]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.5806, 10.8008,  7.5570,  4.5064, 10.8008,  5.8400, 10.0811,  7.9825,
         9.3783,  6.0374, 10.8008,  5.1598,  4.9939,  9.0434,  3.7665, 10.2741],
       device='cuda:0')
This is the output:  tensor([[8.2109],
        [8.3828],
        [8.2188],
        [8.2266],
        [8.0078],
        [8.2109],
        [8.1641],
        [8.1719],
        [8.1562],
        [8.1562],
        [8.2109],
        [8.0312],
        [8.2109],
        [8.3828],
        [8.3828],
        [8.3828]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.0165, 10.8008,  8.8012,  2.8911, 10.8008,  9.6851, 10.0637,  6.0948,
        10.6368, 10.6732,  5.0604,  8.6136,  9.3904,  6.4486,  5.1310,  3.4694],
       device='cuda:0')
This is the output:  tensor([[8.0781],
        [8.1953],
        [8.0781],
        [7.9961],
        [8.0781],
        [8.1406],
        [8.1562],
        [8.0312],
        [8.0938],
        [8.3672],
        [7.9961],
        [8.0938],
        [8.2031],
        [8.3672],
        [8.0312],
        [8.2031]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.3779,  8.8165, 10.8008,  9.3756, 10.4347, 10.8008,  7.4336,  4.4720,
         9.3653,  9.1254,  9.8850, 10.8008, 10.8008,  9.3749,  7.9487, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.1406],
        [8.0859],
        [7.9883],
        [8.1953],
        [8.1328],
        [8.1328],
        [8.3516],
        [8.3516],
        [8.3594],
        [7.9883],
        [7.9883],
        [8.2031],
        [8.2031],
        [8.1406],
        [8.2031],
        [8.1406]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.6473, 10.8008,  6.1585,  6.4656,  9.2971,  9.8561,  5.2673,  9.3626,
        10.8008, 10.8008, 10.8008,  8.8457,  4.3499,  6.2979,  9.8510,  9.5587],
       device='cuda:0')
This is the output:  tensor([[8.1406],
        [8.3516],
        [8.2109],
        [8.3516],
        [8.3516],
        [8.0859],
        [8.0156],
        [8.0781],
        [8.3516],
        [8.0859],
        [8.0156],
        [8.0000],
        [8.2031],
        [8.1406],
        [8.1406],
        [8.3516]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.8008, 10.6434,  4.5735,  7.6216,  6.4706, 10.8008,  9.4764,
        10.8008, 10.1548,  9.0459, 10.0182, 10.8008,  9.7513,  4.6239, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.0078]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([9.9640], device='cuda:0')
This is the output:  tensor([[8.1562],
        [8.2188],
        [8.1016],
        [8.2109],
        [8.3516],
        [8.1562],
        [8.3672],
        [8.0859],
        [8.3672],
        [8.1641],
        [8.1953],
        [8.1406],
        [8.2031],
        [8.0234],
        [8.0000],
        [8.0234]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.8008,  8.1801,  4.7376, 10.8008,  9.2493, 10.8008,  6.6234,
        10.0487,  8.6459, 10.8008, 10.6732,  6.8974,  8.6136,  9.5656,  5.8400],
       device='cuda:0')
This is the output:  tensor([[8.2109],
        [8.0938],
        [8.1484],
        [8.0312],
        [8.3672],
        [8.1016],
        [8.0312],
        [8.2109],
        [8.2109],
        [8.0312],
        [8.2188],
        [8.3750],
        [8.0234],
        [8.0469],
        [8.1562],
        [8.1094]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 3.2356,  6.0799, 10.8008,  9.1210,  9.3761,  8.7458,  8.6527,  9.5670,
        10.8008, 10.8008,  1.5437,  4.8644,  9.3087,  8.4477,  9.2554,  9.5294],
       device='cuda:0')
This is the output:  tensor([[8.0312],
        [8.1172],
        [8.3672],
        [8.1094],
        [8.0312],
        [8.3750],
        [8.1094],
        [8.2188],
        [8.1641],
        [8.3750],
        [8.1719],
        [8.0312],
        [8.2188],
        [8.3828],
        [8.3750],
        [8.2266]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.9838,  2.7386,  5.2673,  7.8266, 10.0182,  7.6878, 10.8008, 10.8008,
         9.7631,  7.7130,  4.9939,  9.0434,  8.6835,  8.7301,  7.5570, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.3750],
        [8.1094],
        [8.3672],
        [8.0391],
        [8.2266],
        [8.0547],
        [8.1719],
        [8.2188],
        [8.1797],
        [8.2109],
        [8.1094],
        [8.3672],
        [8.0391],
        [8.3750],
        [8.1719],
        [8.0312]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.1592,  9.3653,  6.1896,  9.0459, 10.8008, 10.4675,  9.3509, 10.8008,
         4.6065,  5.0916,  7.9825, 10.3338,  9.5806,  9.3783,  6.2477,  9.9640],
       device='cuda:0')
This is the output:  tensor([[8.1172],
        [8.3750],
        [8.1719],
        [8.1172],
        [8.1641],
        [8.3750],
        [8.3828],
        [8.3828],
        [8.2266],
        [8.2266],
        [8.2109],
        [8.3750],
        [8.0391],
        [8.1328],
        [8.0469],
        [8.1250]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.4706,  3.4694,  9.5587,  8.6955, 10.8008,  9.0775,  9.5059, 10.4450,
         7.5111,  9.2412, 10.8008,  7.3194, 10.8008,  5.3640, 10.8008,  8.6061],
       device='cuda:0')
This is the output:  tensor([[8.1250],
        [8.3828],
        [8.1797],
        [8.2344],
        [8.2266],
        [8.0312],
        [8.1094],
        [8.0312],
        [8.2266],
        [8.1953],
        [8.1719],
        [8.0625],
        [8.1328],
        [8.2344],
        [8.3828],
        [8.2344]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.8008, 10.8008,  9.8510, 10.8008,  9.1332,  8.3428,  9.8036,
         9.8237, 10.1073,  5.3808, 10.8008,  2.6868,  8.3977,  8.6913,  8.8457],
       device='cuda:0')
This is the output:  tensor([[8.2578],
        [8.3906],
        [8.3984],
        [8.3906],
        [8.1797],
        [8.1328],
        [8.1406],
        [8.2500],
        [8.3984],
        [8.1328],
        [8.0781],
        [8.1875],
        [8.0547],
        [8.3906],
        [8.0547],
        [8.2500]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.0671,  9.5176, 10.8008,  7.4624,  8.7488,  8.9015,  7.8635, 10.8008,
         9.5890, 10.2741,  7.9487,  4.6239,  7.2902, 10.8008,  9.0067, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.2031],
        [8.2031],
        [8.1875],
        [8.2578],
        [8.3984],
        [8.2656],
        [8.3984],
        [8.2109],
        [8.3984],
        [8.0859],
        [8.1406],
        [8.2578],
        [8.3984],
        [8.1953],
        [8.2188],
        [8.3984]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.7896,  6.4588,  4.3061, 10.7521,  4.6932,  8.5321,  4.5735,  9.7051,
        10.8008,  7.0692,  4.1199,  5.9598,  9.4968, 10.8008,  5.0705,  8.5008],
       device='cuda:0')
This is the output:  tensor([[8.2656],
        [8.0703],
        [8.2656],
        [8.4062],
        [8.0703],
        [8.2031],
        [8.4062],
        [8.1562],
        [8.0703],
        [8.4062],
        [8.1406],
        [8.2656],
        [8.1406],
        [8.4141],
        [8.2578],
        [8.0547]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.5064, 10.8008,  2.8911,  9.3749, 10.8008,  1.6376,  9.8093,  4.3204,
        10.8008,  5.4878, 10.4347, 10.6434, 10.8008, 10.8008,  9.2983,  6.1585],
       device='cuda:0')
This is the output:  tensor([[8.1484],
        [8.1406],
        [8.4062],
        [8.1562],
        [8.2031],
        [8.0859],
        [8.2734],
        [8.1484],
        [8.1953],
        [8.0625],
        [8.4062],
        [8.2656],
        [8.0703],
        [8.1484],
        [8.4062],
        [8.0625]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.1610,  5.3436,  9.5651,  4.0481,  6.2979,  5.0042,  2.7156, 10.1548,
        10.6368,  4.5797,  3.7665, 10.8008,  3.4600,  7.3562, 10.8008,  9.8850],
       device='cuda:0')
This is the output:  tensor([[8.4062],
        [8.2109],
        [8.1484],
        [8.1562],
        [8.2109],
        [8.1406],
        [8.1719],
        [8.1406],
        [8.1719],
        [8.0625],
        [8.2109],
        [8.0703],
        [8.2500],
        [8.4062],
        [8.2031],
        [8.0625]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  7.4336, 10.8008,  6.0374,  6.0948,  9.3229,  9.2675, 10.7103,
         2.5178,  8.4995,  3.3253, 10.8008, 10.0165,  9.4146,  9.7513, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.1641],
        [8.4062],
        [8.0625],
        [8.1016],
        [8.2656],
        [8.1484],
        [8.2109],
        [8.2500],
        [8.0625],
        [8.2031],
        [8.2656],
        [8.4062],
        [8.4062],
        [8.4062],
        [8.1484],
        [8.2188]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.7901, 10.8008,  9.4179,  4.4720,  8.0960, 10.8008,  9.2869,  9.6851,
         4.4405,  9.2971, 10.7407,  9.3626,  7.6216,  9.1172, 10.8008,  5.7579],
       device='cuda:0')
This is the output:  tensor([[8.2109],
        [8.2812],
        [8.0703],
        [8.1562],
        [8.0781],
        [8.1641],
        [8.0703],
        [8.2578],
        [8.2734],
        [8.4219],
        [8.1484],
        [8.0781],
        [8.2578],
        [8.0781],
        [8.0938],
        [8.2109]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.6473,  3.7116, 10.6173, 10.8008, 10.8008,  5.5699, 10.8008, 10.2597,
         7.2419,  9.2336, 10.0811,  7.0435,  8.8012,  3.1579,  3.8380,  4.2921],
       device='cuda:0')
This is the output:  tensor([[8.4062],
        [8.1562],
        [8.0781],
        [8.2188],
        [8.0703],
        [8.4062],
        [8.4141],
        [8.2734],
        [8.2031],
        [8.2578],
        [8.4141],
        [8.4141],
        [8.4062],
        [8.2031],
        [8.4062],
        [8.0938]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.4900,  6.1131,  6.3927,  9.2624,  9.3756, 10.8008,  5.3357,  8.4658,
         9.8561,  9.3904,  9.1254,  6.4486, 10.8008, 10.8008,  3.7740,  8.3599],
       device='cuda:0')
This is the output:  tensor([[8.2578],
        [8.2734],
        [8.2578],
        [8.0703],
        [8.4219],
        [8.2578],
        [8.1484],
        [8.2812],
        [8.2656],
        [8.2031],
        [8.4141],
        [8.0781],
        [8.0703],
        [8.4219],
        [8.2266],
        [8.1719]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.4764,  4.3499,  8.8165, 10.8008,  8.3956,  5.0604,  7.3779,  6.0384,
         6.4656,  5.1883,  5.8236,  2.6171, 10.8008,  3.0530, 10.0027,  7.6966],
       device='cuda:0')
This is the output:  tensor([[8.2031],
        [8.2734],
        [8.4141],
        [8.2656],
        [8.2812],
        [8.1484],
        [8.2734],
        [8.1797],
        [8.2031],
        [8.2656],
        [8.4219],
        [8.2656],
        [8.2266],
        [8.2031],
        [8.2656],
        [8.4141]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.1819,  5.1598,  9.1644,  4.5714,  5.8157,  9.4764,  4.5833,  9.5364,
         8.8265,  9.6373,  5.1310, 10.8008, 10.8008, 10.4156, 10.8008, 10.0481],
       device='cuda:0')
This is the output:  tensor([[8.0859],
        [8.2656],
        [8.4297],
        [8.1719],
        [8.1094],
        [8.2109],
        [8.4219],
        [8.2188],
        [8.2188],
        [8.1016],
        [8.4141],
        [8.2188],
        [8.4141],
        [8.4297],
        [8.4219],
        [8.2188]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  8.8291,  3.2422,  9.6701,  3.0132, 10.8008,  7.1150, 10.8008,
         2.0179, 10.8008, 10.8008, 10.0637, 10.8008,  7.9662,  9.4457,  9.5263],
       device='cuda:0')
This is the output:  tensor([[8.2188]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([9.6113], device='cuda:0')
This is the output:  tensor([[8.4219],
        [8.1641],
        [8.2734],
        [8.1562],
        [8.4297],
        [8.4219],
        [8.4219],
        [8.0938],
        [8.1641],
        [8.1016],
        [8.2656],
        [8.2344],
        [8.2188],
        [8.2188],
        [8.1797],
        [8.2734]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.5570, 10.8008,  3.2356, 10.7103, 10.8008,  9.3761,  9.3783,  4.9838,
         7.9825,  9.5806, 10.8008,  4.9939, 10.8008, 10.6368,  8.6061,  6.8974],
       device='cuda:0')
This is the output:  tensor([[8.0938],
        [8.4297],
        [8.2188],
        [8.0938],
        [8.2656],
        [8.2422],
        [8.2188],
        [8.2891],
        [8.4297],
        [8.2969],
        [8.1797],
        [8.1797],
        [8.2344],
        [8.2188],
        [8.1641],
        [8.1641]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 3.1579, 10.8008,  5.1883, 10.8008,  9.3904,  9.7051, 10.8008,  6.0384,
         7.3194,  3.7116,  9.6701,  9.7901,  9.2624,  9.1819, 10.8008,  6.6234],
       device='cuda:0')
This is the output:  tensor([[8.1016],
        [8.2266],
        [8.4375],
        [8.1250],
        [8.2266],
        [8.1016],
        [8.1875],
        [8.2266],
        [8.4297],
        [8.2188],
        [8.4297],
        [8.2969],
        [8.2266],
        [8.4297],
        [8.0859],
        [8.2188]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.0637,  5.1310,  4.4720,  9.2554,  9.9640,  7.8635,  2.0179,
         9.3749,  9.8561, 10.0481,  5.8157, 10.8008,  4.6932, 10.8008,  5.3808],
       device='cuda:0')
This is the output:  tensor([[8.0859],
        [8.1016],
        [8.2812],
        [8.0859],
        [8.1641],
        [8.4297],
        [8.4375],
        [8.2891],
        [8.1953],
        [8.2734],
        [8.2344],
        [8.2266],
        [8.4297],
        [8.1094],
        [8.1250],
        [8.1250]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.6173, 10.8008,  9.2412,  9.8036,  7.3779,  9.8093,  4.8644,  8.3977,
         5.3640,  9.6851, 10.8008, 10.4156,  7.6878,  9.1210,  7.0692, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.4297],
        [8.1719],
        [8.2812],
        [8.2500],
        [8.4375],
        [8.2422],
        [8.2031],
        [8.1797],
        [8.1172],
        [8.2891],
        [8.2031],
        [8.4375],
        [8.2578],
        [8.1797],
        [8.2891],
        [8.2891]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3626, 10.0811,  8.8165, 10.1073,  7.4624,  9.2493,  9.5364,  7.8266,
         5.8400,  9.2983,  2.5178,  8.6913,  5.0705,  6.1131,  8.4658, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.1797],
        [8.1875],
        [8.1016],
        [8.2969],
        [8.2891],
        [8.2969],
        [8.1797],
        [8.1172],
        [8.4453],
        [8.2344],
        [8.1016],
        [8.1875],
        [8.4375],
        [8.4297],
        [8.4375],
        [8.2969]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  4.3204, 10.8008,  4.5833,  9.6373, 10.8008,  8.6955,  3.8380,
         7.9662,  8.6473,  6.3927,  8.1801,  9.1644, 10.8008,  3.4694,  8.8457],
       device='cuda:0')
This is the output:  tensor([[8.1797],
        [8.1797],
        [8.4375],
        [8.2969],
        [8.2891],
        [8.4375],
        [8.2344],
        [8.4297],
        [8.4375],
        [8.1172],
        [8.4297],
        [8.4375],
        [8.4375],
        [8.0938],
        [8.4453],
        [8.0938]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.1610,  8.9015,  5.4878,  7.5111,  9.8237,  9.0775,  6.2979, 10.8008,
         8.5008,  8.3599, 10.8008,  9.1254,  9.4146, 10.8008,  9.2336,  8.4995],
       device='cuda:0')
This is the output:  tensor([[8.4453],
        [8.2891],
        [8.1719],
        [8.4375],
        [8.3047],
        [8.4375],
        [8.2969],
        [8.2891],
        [8.2891],
        [8.2500],
        [8.4375],
        [8.1953],
        [8.2422],
        [8.1719],
        [8.2969],
        [8.2266]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.4450,  6.4656,  9.4764, 10.3338,  6.0671, 10.8008, 10.8008, 10.8008,
         8.8291,  5.7579,  3.7740,  4.0481,  9.3509, 10.4347,  4.3499,  8.8265],
       device='cuda:0')
This is the output:  tensor([[8.2266],
        [8.0938],
        [8.2422],
        [8.4453],
        [8.1328],
        [8.2969],
        [8.2422],
        [8.1953],
        [8.2969],
        [8.4453],
        [8.1094],
        [8.2422],
        [8.4375],
        [8.2812],
        [8.2500],
        [8.4375]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.8008,  1.6376,  8.3956, 10.4675, 10.8008,  4.6239,  6.0374,
        10.7407,  3.0530, 10.0182,  6.2477,  9.1172, 10.8008,  7.4336,  5.2673],
       device='cuda:0')
This is the output:  tensor([[8.2969],
        [8.2266],
        [8.4375],
        [8.1094],
        [8.2891],
        [8.2891],
        [8.0938],
        [8.4375],
        [8.1328],
        [8.1094],
        [8.1797],
        [8.2969],
        [8.1172],
        [8.1797],
        [8.1797],
        [8.4453]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.8510,  4.3061,  7.6216,  9.3087, 10.8008,  8.6835,  6.1585,  9.4968,
         3.0132, 10.8008, 10.8008, 10.8008, 10.8008,  4.1199, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.1172],
        [8.4375],
        [8.4375],
        [8.2266],
        [8.2500],
        [8.4375],
        [8.1797],
        [8.1719],
        [8.4375],
        [8.0938],
        [8.4453],
        [8.2969],
        [8.1094],
        [8.4453],
        [8.2422],
        [8.1797]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.6527, 10.8008, 10.8008, 10.6732,  6.4588, 10.8008,  6.4706,  8.3428,
         6.1896,  9.5656,  4.1592,  2.8911, 10.8008,  9.5059,  4.2921,  7.3562],
       device='cuda:0')
This is the output:  tensor([[8.4375],
        [8.4453],
        [8.4453],
        [8.2031],
        [8.2891],
        [8.3047],
        [8.4375],
        [8.2969],
        [8.2969],
        [8.1953],
        [8.1328],
        [8.1953],
        [8.2891],
        [8.4375],
        [8.1719],
        [8.4375]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 3.7665,  9.5890,  6.4486,  9.2675,  8.8012,  2.7156, 10.8008,  4.7376,
        10.7521,  7.6966,  7.9487,  2.7386, 10.8008,  9.5176,  6.0799, 10.4900],
       device='cuda:0')
This is the output:  tensor([[8.3047],
        [8.2266],
        [8.2969],
        [8.1797],
        [8.4375],
        [8.2969],
        [8.2969],
        [8.2422],
        [8.2500],
        [8.2969],
        [8.1094],
        [8.2891],
        [8.3047],
        [8.0938],
        [8.4375],
        [8.0938]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.2971,  4.5064, 10.1548, 10.8008,  5.9598,  5.1598, 10.8008,
         6.0948, 10.8008,  3.4600,  9.5670,  8.5321,  9.1332,  5.8236,  9.8850],
       device='cuda:0')
This is the output:  tensor([[8.3047],
        [8.2422],
        [8.2422],
        [8.1719],
        [8.4375],
        [8.1953],
        [8.0938],
        [8.2812],
        [8.4375],
        [8.1172],
        [8.4453],
        [8.1094],
        [8.1172],
        [8.1719],
        [8.2578],
        [8.4375]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.6434,  9.6113,  9.7513,  9.3229,  9.5651,  9.5294,  9.4179,  9.4764,
         9.4457,  5.0042,  8.7301,  9.0067, 10.8008,  5.3436,  8.6459,  4.5735],
       device='cuda:0')
This is the output:  tensor([[8.1094],
        [8.1094],
        [8.2500],
        [8.2344],
        [8.2344],
        [8.2266],
        [8.0938],
        [8.4375],
        [8.4453],
        [8.1094],
        [8.1797],
        [8.2500],
        [8.2500],
        [8.2500],
        [8.2812],
        [8.1172]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  7.2902,  4.6065,  9.2869,  9.5263, 10.8008,  4.4405, 10.8008,
        10.0487,  2.6171,  8.7458, 10.0027, 10.8008,  5.7896, 10.0165, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.2344],
        [8.1172],
        [8.1953],
        [8.1797],
        [8.2266],
        [8.2891],
        [8.2500],
        [8.4453],
        [8.1797],
        [8.1172],
        [8.0938],
        [8.2891],
        [8.1797],
        [8.2812],
        [8.0938],
        [8.4375]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.7631,  9.0459,  2.6868,  9.3653,  8.7488,  4.5714,  3.3253,  5.3357,
        10.8008,  8.6136,  4.5797, 10.8008, 10.8008, 10.2597,  9.3756,  7.7130],
       device='cuda:0')
This is the output:  tensor([[8.1094],
        [8.2500],
        [8.2812],
        [8.4375],
        [8.2891],
        [8.3047],
        [8.4453],
        [8.2969],
        [8.2969],
        [8.0938],
        [8.4453],
        [8.2812],
        [8.2344],
        [8.1797],
        [8.1953],
        [8.1328]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.0434, 10.8008,  5.0604, 10.8008, 10.8008,  7.2419,  7.1150,  8.0960,
         1.5437, 10.8008,  3.2422,  5.0916,  9.5587, 10.2741,  5.5699,  8.4477],
       device='cuda:0')
This is the output:  tensor([[8.1094]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([7.0435], device='cuda:0')
  return F.mse_loss(input, target, reduction=self.reduction)
Training:   0%|                                                                                                                                               | 0/18 [00:00<?, ?it/s]
Epoch 10: Train Loss = 6.0670, Val Loss = 5.4070
This is the output:  tensor([[8.0938],
        [8.2891],
        [8.2891],
        [8.2266],
        [8.1797],
        [8.1797],
        [8.2891],
        [8.4375],
        [8.4375],
        [8.1797],
        [8.2266],
        [8.2969],
        [8.2891],
        [8.1719],
        [8.2266],
        [8.4297]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  4.5714, 10.8008, 10.4156,  9.3653, 10.8008,  9.2983,  9.3749,
         9.4457,  4.1199,  8.7488,  8.3977,  8.8291, 10.8008,  4.3061, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.3828],
        [8.2422],
        [8.0703],
        [8.1406],
        [8.3750],
        [8.2344],
        [8.3750],
        [8.3828],
        [8.1953],
        [8.1250],
        [8.2500],
        [8.0469],
        [8.0625],
        [8.1406],
        [8.2500],
        [8.0703]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.8008,  5.0042,  2.7386, 10.8008,  3.2356,  5.4878,  4.1592,
         6.4588,  5.3436,  7.2419,  4.4405, 10.0182,  4.0481, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.1484],
        [8.2812],
        [7.9727],
        [8.2812],
        [7.9844],
        [8.0703],
        [8.1562],
        [8.1016],
        [8.0078],
        [8.2812],
        [7.9922],
        [7.9922],
        [8.2812],
        [8.1406],
        [8.0469],
        [7.9844]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  7.6878,  9.1332,  9.3626,  2.6171,  5.3640,  4.3499,  6.2477,
         4.4720, 10.8008,  9.0459, 10.8008, 10.8008, 10.8008,  7.8266,  9.0434],
       device='cuda:0')
This is the output:  tensor([[7.8828],
        [7.8711],
        [8.1562],
        [8.1484],
        [7.9961],
        [7.9336],
        [8.0234],
        [8.0312],
        [7.9336],
        [7.9883],
        [7.9805],
        [8.0234],
        [8.0469],
        [8.1641],
        [7.9453],
        [7.8945]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.4179,  5.1310, 10.8008, 10.8008,  6.0799,  8.8165,  6.8974,
         8.3428,  8.6473, 10.8008,  9.4764,  6.0671,  3.0530, 10.8008,  9.5806],
       device='cuda:0')
This is the output:  tensor([[7.9023],
        [8.0781],
        [7.9805],
        [7.8398],
        [7.8398],
        [7.9648],
        [8.0781],
        [7.9336],
        [8.0703],
        [7.9336],
        [8.0859],
        [7.8281],
        [7.9648],
        [7.9258],
        [7.9258],
        [7.8945]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.2675,  8.5008,  5.8157,  3.8380,  8.3599, 10.8008,  9.4146,  9.2493,
         5.2673,  4.6065,  5.3357,  4.9838,  9.8237,  6.2979,  9.2554,  5.5699],
       device='cuda:0')
This is the output:  tensor([[7.8047],
        [7.9727],
        [7.7930],
        [7.9688],
        [7.7656],
        [7.9648],
        [7.7852],
        [7.7422],
        [7.9727],
        [7.9648],
        [7.8789],
        [7.9688],
        [7.8711],
        [7.8047],
        [7.7656],
        [7.9648]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.0374,  9.5059,  8.7458,  3.7665,  8.4477,  9.1172,  9.4764, 10.8008,
         7.1150, 10.8008,  8.5321,  9.0775, 10.7407,  9.7901, 10.4675,  4.5735],
       device='cuda:0')
This is the output:  tensor([[7.7930],
        [7.8164],
        [7.7500],
        [7.8203],
        [7.8164],
        [7.9141],
        [7.6953],
        [7.9141],
        [7.8320],
        [7.7500],
        [7.8086],
        [7.7930],
        [7.8164],
        [7.7500],
        [7.7578],
        [7.8203]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.0027, 10.8008,  5.1610, 10.7521, 10.8008,  9.4968, 10.6173,  7.5570,
         6.0384, 10.2741,  5.0705, 10.8008,  9.6373,  6.1131,  7.6966,  4.5833],
       device='cuda:0')
This is the output:  tensor([[7.7578],
        [7.7812],
        [7.7500],
        [7.7734],
        [7.8203],
        [7.7734],
        [7.8203],
        [7.8203],
        [7.7969],
        [7.9062],
        [7.9062],
        [7.8203],
        [7.7383],
        [7.9023],
        [7.8047],
        [7.8984]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.5294,  1.6376,  8.9015, 10.6368,  2.8911, 10.6732,  8.8457, 10.8008,
         8.6459, 10.4450,  4.8644,  1.5437,  7.3779,  5.8236, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[7.7617],
        [7.7734],
        [7.8477],
        [7.7188],
        [7.7031],
        [7.7305],
        [7.7734],
        [7.7031],
        [7.7383],
        [7.7383],
        [7.7891],
        [7.6719],
        [7.7383],
        [7.6719],
        [7.8516],
        [7.6719]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.0604,  8.4658, 10.8008,  4.3204,  6.6234,  9.8561,  9.8510, 10.7103,
         9.7631,  9.5587,  3.7116, 10.8008, 10.8008,  3.1579,  9.1644,  6.3927],
       device='cuda:0')
This is the output:  tensor([[7.7695],
        [7.7695],
        [7.7305],
        [7.8398],
        [7.7305],
        [7.7461],
        [7.7305],
        [7.7695],
        [7.7227],
        [7.6797],
        [7.8438],
        [7.6680],
        [7.6797],
        [7.6992],
        [7.7383],
        [7.6680]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.5064, 10.8008, 10.8008,  9.3783,  9.5364,  5.7579,  9.1819, 10.8008,
         2.6868,  7.2902,  6.4486, 10.8008, 10.8008,  3.0132,  4.6239,  9.3756],
       device='cuda:0')
This is the output:  tensor([[7.7422],
        [7.7812],
        [7.8789],
        [7.8672],
        [7.7539],
        [7.8711],
        [7.8789],
        [7.7656],
        [7.8711],
        [7.7773],
        [7.8789],
        [7.7539],
        [7.8125],
        [7.7109],
        [7.7617],
        [7.7109]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.9487,  9.2624,  8.3956,  9.3761, 10.8008, 10.8008,  8.7301,  8.8265,
         4.6932,  2.0179, 10.8008, 10.8008, 10.6434, 10.8008,  8.1801,  4.5797],
       device='cuda:0')
This is the output:  tensor([[7.8711],
        [7.7969],
        [7.8398],
        [7.7852],
        [7.8789],
        [7.9414],
        [7.8477],
        [7.8711],
        [7.8047],
        [7.8242],
        [7.8477],
        [7.9414],
        [7.8555],
        [7.8711],
        [7.9336],
        [7.8164]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.2412,  3.4600, 10.8008, 10.8008,  5.9598,  9.5651, 10.8008, 10.8008,
         5.8400, 10.8008,  9.7513,  3.4694,  4.9939,  8.6835, 10.3338,  7.0692],
       device='cuda:0')
This is the output:  tensor([[7.9766],
        [7.9414],
        [7.9414],
        [7.9414],
        [7.9258],
        [7.9648],
        [7.9766],
        [7.9258],
        [8.0391],
        [8.0391],
        [7.8984],
        [7.9570],
        [7.9102],
        [7.9492],
        [7.8867],
        [7.8984]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.1598,  9.2971,  5.1883,  5.3808, 10.8008, 10.2597,  4.7376, 10.1548,
         9.1254,  8.6913,  9.9640,  3.3253,  8.6136, 10.8008,  8.4995,  7.0435],
       device='cuda:0')
This is the output:  tensor([[8.1172],
        [8.0234],
        [7.9961],
        [8.0547],
        [8.0547],
        [8.0391],
        [8.0469],
        [8.0469],
        [8.0312],
        [8.1094],
        [8.0312],
        [7.9727],
        [8.1172],
        [8.0078],
        [8.0078],
        [8.1094]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.5890,  9.6701, 10.8008,  6.4656,  8.8012,  7.4336,  9.3904,  9.7051,
         2.5178, 10.8008, 10.0637,  6.1585, 10.8008, 10.8008,  8.6955,  3.7740],
       device='cuda:0')
This is the output:  tensor([[8.1172],
        [8.2188],
        [8.1797],
        [8.1406],
        [8.1406],
        [8.1719],
        [8.1250],
        [8.0859],
        [8.1719],
        [8.2344],
        [8.1406],
        [8.1406],
        [8.1016],
        [8.1172],
        [8.1328],
        [8.1562]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.0811,  9.5176,  2.7156,  9.3509,  4.2921,  8.0960,  6.4706,  9.5656,
        10.8008,  9.2336,  9.5263,  9.6113, 10.8008, 10.4347, 10.8008,  5.0916],
       device='cuda:0')
This is the output:  tensor([[8.2578],
        [8.2578],
        [8.3125],
        [8.2812],
        [8.3672],
        [8.3672],
        [8.3047],
        [8.3672],
        [8.2344],
        [8.3672],
        [8.2422],
        [8.2578],
        [8.3672],
        [8.3672],
        [8.3828],
        [8.3750]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.6527,  9.3229,  7.5111,  7.8635,  7.6216, 10.4900, 10.1073, 10.8008,
         9.8850,  7.3194,  9.3087,  9.1210,  7.4624,  9.8093,  7.9662, 10.0487],
       device='cuda:0')
This is the output:  tensor([[8.4844],
        [8.4141],
        [8.5469],
        [8.4453],
        [8.4453],
        [8.4688],
        [8.4141],
        [8.4141],
        [8.5547],
        [8.4062],
        [8.4531],
        [8.5469],
        [8.4766],
        [8.5469],
        [8.4609],
        [8.4766]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.5670, 10.8008,  7.7130,  7.9825,  7.3562,  5.7896, 10.8008,  9.0067,
         3.2422,  9.8036,  8.6061, 10.0481, 10.0165,  6.1896,  9.2869,  9.6851],
       device='cuda:0')
This is the output:  tensor([[8.6641]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([6.0948], device='cuda:0')
This is the output:  tensor([[8.8672],
        [8.7344],
        [8.8125],
        [8.8047],
        [8.8125],
        [8.7578],
        [8.7344],
        [8.7891],
        [8.8047],
        [8.7734],
        [8.7734],
        [8.8672],
        [8.7188],
        [8.7578],
        [8.7578],
        [8.8125]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.3194,  9.9640, 10.7521,  8.8012,  4.7376, 10.8008,  2.6171,  9.2493,
        10.8008,  5.5699, 10.8008,  5.8236, 10.8008, 10.8008,  8.9015,  4.3499],
       device='cuda:0')
This is the output:  tensor([[8.8750],
        [8.9219],
        [8.9297],
        [8.9297],
        [8.8281],
        [8.8594],
        [8.7969],
        [8.8281],
        [8.8438],
        [8.8359],
        [8.9219],
        [8.8594],
        [8.8750],
        [8.8203],
        [8.8438],
        [8.8438]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.9598,  6.1896,  9.5059,  9.4457,  8.6955,  5.0604, 10.8008, 10.8008,
         2.6868,  7.9487,  9.3626,  3.3253, 10.8008, 10.8008,  8.7488,  7.6966],
       device='cuda:0')
This is the output:  tensor([[8.9375],
        [8.8203],
        [8.9375],
        [8.9531],
        [8.9375],
        [8.8438],
        [8.8672],
        [8.8203],
        [8.8828],
        [8.8594],
        [8.8828],
        [8.8906],
        [8.9375],
        [8.8750],
        [8.8906],
        [8.8359]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.4878, 10.6173, 10.8008,  9.2336,  9.5176, 10.8008,  4.3204,  9.5656,
        10.0165, 10.6732,  5.0916,  9.2983, 10.8008,  2.5178,  8.6459,  6.3927],
       device='cuda:0')
This is the output:  tensor([[8.8594],
        [8.9062],
        [8.8203],
        [8.9062],
        [8.8047],
        [8.8359],
        [8.8516],
        [8.8594],
        [8.8594],
        [8.8438],
        [8.9062],
        [8.8281],
        [8.9062],
        [8.9062],
        [8.9062],
        [8.8359]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.1172, 10.7103,  3.7665,  4.5797,  9.1819,  5.3640,  3.2356,
         9.2412,  9.2869,  5.2673,  8.6527,  9.1254,  7.6216,  9.3783, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.7891],
        [8.7734],
        [8.7734],
        [8.8047],
        [8.8359],
        [8.7891],
        [8.7969],
        [8.8359],
        [8.7656],
        [8.7891],
        [8.7656],
        [8.7812],
        [8.7500],
        [8.8438],
        [8.8359],
        [8.7812]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.4764,  5.1610,  9.0459, 10.8008, 10.8008, 10.8008,  9.2675,  9.3761,
        10.8008, 10.0027, 10.8008,  6.2979,  9.4179,  9.5890,  3.7740,  9.5587],
       device='cuda:0')
This is the output:  tensor([[8.7734],
        [8.7578],
        [8.7734],
        [8.8125],
        [8.7969],
        [8.7422],
        [8.7734],
        [8.7656],
        [8.7969],
        [8.7969],
        [8.8203],
        [8.7656],
        [8.7656],
        [8.7969],
        [8.7812],
        [8.7891]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.6239,  7.3779,  6.2477, 10.8008,  6.0671,  4.4405,  9.7901, 10.2741,
         2.7156, 10.6434, 10.0481,  4.3061,  8.8265,  7.2419,  9.6373,  9.5364],
       device='cuda:0')
This is the output:  tensor([[8.7656],
        [8.7109],
        [8.7109],
        [8.7344],
        [8.7031],
        [8.7266],
        [8.7578],
        [8.7266],
        [8.7344],
        [8.7109],
        [8.7578],
        [8.7266],
        [8.7656],
        [8.7266],
        [8.7344],
        [8.7031]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.1592,  9.0067, 10.8008,  3.0132,  9.8850, 10.8008, 10.8008,  5.8400,
         8.3977,  3.1579, 10.8008,  5.7579,  5.1310,  9.6701,  5.1598, 10.0811],
       device='cuda:0')
This is the output:  tensor([[8.6406],
        [8.6328],
        [8.6562],
        [8.6719],
        [8.6484],
        [8.6328],
        [8.6328],
        [8.6641],
        [8.6562],
        [8.6484],
        [8.6328],
        [8.6641],
        [8.6641],
        [8.6484],
        [8.6484],
        [8.6328]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.8974, 10.8008,  8.4477, 10.8008,  2.8911,  7.3562, 10.0637, 10.8008,
         4.4720,  8.8457,  1.6376, 10.8008, 10.8008,  4.5833, 10.8008,  9.7631],
       device='cuda:0')
This is the output:  tensor([[8.5312],
        [8.5312],
        [8.5156],
        [8.5234],
        [8.5234],
        [8.5234],
        [8.5312],
        [8.5234],
        [8.5391],
        [8.5234],
        [8.5234],
        [8.5312],
        [8.5469],
        [8.5078],
        [8.5391],
        [8.5391]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.6136, 10.7407,  2.0179, 10.8008,  9.8237, 10.8008,  4.5064, 10.8008,
         4.5735,  6.4588, 10.0182,  8.3599, 10.0487,  9.8036,  8.5321,  5.8157],
       device='cuda:0')
This is the output:  tensor([[8.3906],
        [8.3828],
        [8.3750],
        [8.3828],
        [8.3750],
        [8.3906],
        [8.4062],
        [8.3906],
        [8.3828],
        [8.3828],
        [8.3906],
        [8.3750],
        [8.3984],
        [8.3906],
        [8.3828],
        [8.3750]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.3357,  7.0435,  7.9825,  7.4336,  9.5263,  1.5437, 10.4675, 10.8008,
        10.4900, 10.8008,  9.4146,  9.7513,  3.0530, 10.1073,  3.4600, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.2188],
        [8.2188],
        [8.2109],
        [8.2188],
        [8.2031],
        [8.2031],
        [8.2266],
        [8.2109],
        [8.2422],
        [8.2188],
        [8.2266],
        [8.2266],
        [8.2188],
        [8.2266],
        [8.2109],
        [8.2031]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.6913,  9.5651,  9.4764, 10.8008,  9.6851, 10.8008,  9.3087,  9.3509,
         9.5806,  9.3756,  7.9662,  9.5294,  4.6065, 10.8008,  6.6234,  9.2971],
       device='cuda:0')
This is the output:  tensor([[8.1016],
        [8.1016],
        [8.1094],
        [8.1094],
        [8.0938],
        [8.1016],
        [8.1172],
        [8.1250],
        [8.1016],
        [8.1016],
        [8.0938],
        [8.0938],
        [8.1016],
        [8.1250],
        [8.1016],
        [8.0938]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008, 10.8008,  8.7301, 10.8008, 10.3338,  5.3436,  7.8635, 10.8008,
         9.5670,  8.3428,  5.3808,  7.7130, 10.8008,  9.0434,  9.2554,  7.4624],
       device='cuda:0')
This is the output:  tensor([[8.0391],
        [8.0625],
        [8.0703],
        [8.0625],
        [8.0938],
        [8.0625],
        [8.0547],
        [8.0547],
        [8.0391],
        [8.0547],
        [8.0469],
        [8.0391],
        [8.0391],
        [8.0547],
        [8.0547],
        [8.0469]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.8561,  3.7116, 10.8008,  6.0374, 10.8008,  8.6061,  7.8266, 10.8008,
         5.1883, 10.8008,  9.6113,  9.8093,  8.8165,  6.0384,  8.7458,  4.2921],
       device='cuda:0')
This is the output:  tensor([[8.0547],
        [8.0469],
        [8.0312],
        [8.0234],
        [8.0312],
        [8.0312],
        [8.0234],
        [8.0312],
        [8.0391],
        [8.0234],
        [8.0703],
        [8.0781],
        [8.0234],
        [8.0391],
        [8.0234],
        [8.0156]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.1801,  9.1332, 10.8008,  4.8644, 10.8008,  7.5111,  6.4656, 10.4347,
         9.2624,  8.3956, 10.8008,  7.0692,  8.6835,  5.7896,  4.5714,  3.4694],
       device='cuda:0')
This is the output:  tensor([[8.0000],
        [7.9883],
        [7.9922],
        [7.9609],
        [7.9688],
        [7.9688],
        [7.9648],
        [8.0000],
        [7.9805],
        [7.9688],
        [7.9648],
        [7.9883],
        [8.0078],
        [7.9961],
        [7.9922],
        [8.0000]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.4995,  6.0948,  9.3653,  4.6932,  9.3904, 10.6368,  6.4486,  2.7386,
         8.6473,  3.2422,  7.1150,  4.9939,  4.9838,  9.7051,  6.4706,  6.1585],
       device='cuda:0')
This is the output:  tensor([[7.8750],
        [7.8867],
        [7.8750],
        [7.8984],
        [7.8750],
        [7.8789],
        [7.8906],
        [7.9219],
        [7.9453],
        [7.9453],
        [7.9102],
        [7.9023],
        [7.8906],
        [7.8906],
        [7.9023],
        [7.9336]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.5570, 10.2597,  9.4968,  8.0960,  9.1644, 10.8008, 10.4156, 10.8008,
         5.0042,  9.1210,  6.1131,  9.3229, 10.8008,  8.8291,  6.0799, 10.8008],
       device='cuda:0')
This is the output:  tensor([[7.8359],
        [7.8516],
        [7.8359],
        [7.8633],
        [7.8359],
        [7.8828],
        [7.8633],
        [7.8359],
        [7.9062],
        [7.8984],
        [7.8867],
        [7.8750],
        [7.8750],
        [7.8359],
        [7.8359],
        [7.8516]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.0775, 10.8008, 10.8008,  8.4658, 10.4450,  5.0705,  9.8510,  9.3749,
         3.8380,  7.2902,  4.0481, 10.1548,  4.1199, 10.8008,  7.6878, 10.8008],
       device='cuda:0')
This is the output:  tensor([[7.8359]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([8.5008], device='cuda:0')
This is the output:  tensor([[7.9180],
        [7.8789],
        [7.8789],
        [7.9062],
        [7.9258],
        [7.8828],
        [7.9609],
        [7.9375],
        [7.8789],
        [7.9180],
        [7.8906],
        [7.9297],
        [7.8945],
        [7.9297],
        [7.9180],
        [7.9258]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.8266,  8.5008,  9.1254, 10.7407,  8.1801, 10.4450,  3.0132,  9.3087,
         5.4878, 10.8008,  8.8165, 10.6173, 10.8008,  9.4179, 10.8008,  4.0481],
       device='cuda:0')
This is the output:  tensor([[8.0312],
        [7.9531],
        [7.9609],
        [7.9805],
        [7.9531],
        [7.9805],
        [7.9570],
        [8.0078],
        [7.9609],
        [7.9883],
        [7.9883],
        [7.9883],
        [8.0078],
        [7.9844],
        [7.9805],
        [7.9609]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.4477, 10.8008, 10.8008,  9.4764,  5.2673, 10.7103,  3.7665,  2.6171,
         8.3956,  7.2419,  7.3562,  4.1199,  7.2902, 10.8008, 10.8008,  9.5059],
       device='cuda:0')
This is the output:  tensor([[8.0547],
        [8.0391],
        [8.0078],
        [8.0156],
        [8.0547],
        [8.0156],
        [8.0078],
        [8.0000],
        [8.0156],
        [8.0469],
        [8.0469],
        [8.0078],
        [8.0234],
        [8.0234],
        [8.0078],
        [8.0156]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 2.5178,  6.1585, 10.0481,  9.2983,  5.3640,  9.2336,  3.4694,  7.6216,
         4.5714, 10.8008,  6.3927, 10.8008, 10.0637, 10.8008,  9.4146, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.0469],
        [8.0391],
        [8.0703],
        [8.0547],
        [8.0312],
        [8.0234],
        [8.0312],
        [8.0625],
        [8.0391],
        [8.0156],
        [8.0078],
        [8.0391],
        [8.0312],
        [8.0469],
        [8.0156],
        [8.0156]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 2.7386,  8.7458,  7.0692,  3.1579,  3.3253,  6.2477,  8.4658, 10.8008,
         9.3756, 10.0165, 10.8008,  8.4995, 10.7521,  6.0374, 10.8008,  8.7488],
       device='cuda:0')
This is the output:  tensor([[7.9922],
        [7.9766],
        [8.0000],
        [7.9922],
        [7.9922],
        [7.9844],
        [7.9922],
        [7.9922],
        [7.9805],
        [7.9922],
        [7.9883],
        [8.0312],
        [7.9844],
        [7.9922],
        [7.9844],
        [8.0156]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.2979,  6.1896,  8.6955,  9.7513,  2.0179, 10.6368,  9.5263,  9.6113,
         7.5570, 10.8008,  7.9662,  8.6527, 10.4156,  9.2554, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.0156],
        [8.0078],
        [8.0312],
        [8.0312],
        [7.9844],
        [8.0312],
        [8.0000],
        [7.9883],
        [8.0078],
        [7.9883],
        [8.0391],
        [8.0156],
        [7.9961],
        [8.0312],
        [7.9922],
        [7.9883]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.6966,  5.8157, 10.8008,  3.8380, 10.8008,  9.0459,  2.8911,  9.1644,
         4.5797,  5.3808, 10.4675, 10.8008, 10.4347,  8.6136,  8.8012,  4.6932],
       device='cuda:0')
This is the output:  tensor([[7.9531],
        [7.9531],
        [7.9531],
        [7.9688],
        [7.9609],
        [7.9883],
        [7.9727],
        [7.9805],
        [7.9609],
        [7.9805],
        [7.9844],
        [7.9531],
        [7.9844],
        [7.9727],
        [7.9609],
        [7.9531]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.6851, 10.8008, 10.8008,  6.4588, 10.8008,  9.5364, 10.8008,  7.8635,
         6.4486,  9.7051,  9.9640, 10.8008,  5.0705, 10.8008,  9.8237,  9.1172],
       device='cuda:0')
This is the output:  tensor([[7.9688],
        [7.9766],
        [7.9688],
        [7.9805],
        [7.9766],
        [7.9883],
        [7.9766],
        [7.9883],
        [7.9844],
        [7.9688],
        [7.9688],
        [7.9766],
        [7.9727],
        [7.9648],
        [7.9688],
        [7.9883]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3783,  4.5064,  8.6835,  4.4405,  8.9015, 10.8008,  9.2493,  9.7901,
         2.7156,  1.6376,  9.5651, 10.8008,  5.1310, 10.8008,  9.2869, 10.8008],
       device='cuda:0')
This is the output:  tensor([[7.9375],
        [7.9531],
        [7.9492],
        [7.9492],
        [7.9414],
        [7.9336],
        [7.9414],
        [7.9336],
        [7.9570],
        [7.9414],
        [7.9453],
        [7.9492],
        [7.9609],
        [7.9492],
        [7.9414],
        [7.9531]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.2597,  5.9598,  5.7896,  3.0530,  9.3229,  9.8561,  9.3749, 10.8008,
        10.6434, 10.0811,  4.1592, 10.8008,  9.0067,  3.2422, 10.4900, 10.8008],
       device='cuda:0')
This is the output:  tensor([[7.9570],
        [7.9570],
        [7.9688],
        [7.9688],
        [7.9766],
        [7.9609],
        [7.9688],
        [7.9609],
        [7.9570],
        [7.9492],
        [7.9609],
        [7.9688],
        [7.9883],
        [7.9531],
        [7.9609],
        [7.9805]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.1332, 10.8008, 10.0182,  8.6061,  9.2675,  8.8457,  6.0384, 10.8008,
         9.5656,  8.3428,  8.3977,  6.0671,  7.9487,  8.8291,  4.3499,  8.3599],
       device='cuda:0')
This is the output:  tensor([[7.9961],
        [8.0000],
        [8.0078],
        [8.0000],
        [8.0000],
        [8.0000],
        [7.9961],
        [8.0156],
        [7.9961],
        [8.0078],
        [8.0078],
        [8.0312],
        [8.0000],
        [8.0000],
        [8.0000],
        [8.0078]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.0604, 10.8008,  7.4624,  6.4656, 10.3338,  9.8850, 10.8008, 10.1073,
         5.3436,  4.8644,  7.7130,  4.4720,  9.5587,  8.6473,  9.6373, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.0859],
        [8.1094],
        [8.0781],
        [8.0781],
        [8.0781],
        [8.0859],
        [8.0703],
        [8.0781],
        [8.0938],
        [8.0859],
        [8.0781],
        [8.0859],
        [8.0859],
        [8.0781],
        [8.0703],
        [8.1016]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.0434, 10.8008, 10.2741,  4.2921, 10.8008,  4.9939,  6.6234, 10.8008,
        10.0487, 10.8008,  6.4706,  8.6913,  5.1598,  4.6239,  9.1819, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.1953],
        [8.2031],
        [8.1953],
        [8.1875],
        [8.2109],
        [8.2031],
        [8.2031],
        [8.1797],
        [8.1953],
        [8.1875],
        [8.2109],
        [8.1953],
        [8.1953],
        [8.1953],
        [8.2031],
        [8.1953]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.6065,  7.3194,  4.7376, 10.8008,  3.7116,  9.5806,  9.1210,  5.0916,
        10.8008,  5.1610,  5.3357,  9.3626,  1.5437,  6.0948,  5.8236,  3.7740],
       device='cuda:0')
This is the output:  tensor([[8.2422],
        [8.2500],
        [8.2344],
        [8.2656],
        [8.2344],
        [8.2656],
        [8.2656],
        [8.2500],
        [8.2734],
        [8.2344],
        [8.2578],
        [8.2500],
        [8.2578],
        [8.2656],
        [8.2734],
        [8.2656]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3904,  9.2624, 10.6732,  9.5176,  5.1883,  9.4968,  8.5321,  4.9838,
         9.5890,  8.8265,  5.8400,  5.7579,  8.0960,  9.3761, 10.8008, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.3438],
        [8.3516],
        [8.3594],
        [8.3359],
        [8.3281],
        [8.3438],
        [8.3359],
        [8.3359],
        [8.3594],
        [8.3594],
        [8.3359],
        [8.3516],
        [8.3672],
        [8.3359],
        [8.3438],
        [8.3438]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 2.6868,  4.5833,  9.4457,  7.0435,  9.2971,  3.2356,  6.1131,  3.4600,
         7.6878,  9.8093, 10.8008,  8.6459,  7.1150, 10.8008, 10.8008,  6.8974],
       device='cuda:0')
This is the output:  tensor([[8.3984],
        [8.3672],
        [8.3906],
        [8.3828],
        [8.4062],
        [8.3906],
        [8.3750],
        [8.4141],
        [8.4062],
        [8.3828],
        [8.3906],
        [8.3906],
        [8.3906],
        [8.3906],
        [8.3750],
        [8.3906]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.8510,  6.0799,  4.3204,  9.4764,  4.5735, 10.8008,  7.9825,  8.7301,
        10.8008, 10.8008, 10.8008,  5.5699, 10.0027,  9.5294,  9.3653,  7.4336],
       device='cuda:0')
This is the output:  tensor([[8.4688],
        [8.4531],
        [8.4609],
        [8.4531],
        [8.4766],
        [8.4453],
        [8.4688],
        [8.4922],
        [8.4688],
        [8.4688],
        [8.4922],
        [8.4609],
        [8.4531],
        [8.4609],
        [8.4609],
        [8.4609]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  7.3779,  9.7631, 10.8008,  7.5111,  9.8036,  5.0042,  9.0775,
         9.6701,  9.2412, 10.8008, 10.8008,  4.3061, 10.8008,  9.3509, 10.1548],
       device='cuda:0')
This is the output:  tensor([[8.5781]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([9.5670], device='cuda:0')
This is the output:  tensor([[8.7031],
        [8.7031],
        [8.7266],
        [8.7031],
        [8.7109],
        [8.6875],
        [8.7578],
        [8.7500],
        [8.7578],
        [8.7109],
        [8.7500],
        [8.6797],
        [8.6953],
        [8.7109],
        [8.7109],
        [8.7109]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  9.0459,  7.5111, 10.8008,  9.6701,  9.9640,  9.5890, 10.4900,
         4.1592,  8.1801, 10.8008,  9.3756, 10.8008,  5.0604,  4.3204, 10.0027],
       device='cuda:0')
This is the output:  tensor([[8.9062],
        [8.8516],
        [8.8828],
        [8.9219],
        [8.8828],
        [8.8828],
        [8.8750],
        [8.8906],
        [8.8438],
        [8.8750],
        [8.9219],
        [8.8672],
        [8.8906],
        [8.8750],
        [8.8516],
        [8.8828]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.0671,  9.0067,  3.3253,  9.3749, 10.8008,  6.4656,  9.2869,  9.8510,
         4.5797,  4.6239,  7.7130, 10.6368, 10.1073,  8.8165,  3.4600,  5.7896],
       device='cuda:0')
This is the output:  tensor([[8.9453],
        [9.0312],
        [8.9609],
        [9.0391],
        [9.0391],
        [8.9766],
        [8.9453],
        [8.9922],
        [8.9922],
        [9.0469],
        [9.0469],
        [9.0312],
        [8.9609],
        [9.0078],
        [9.0312],
        [8.9688]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.8036, 10.8008,  2.6171,  9.4968,  3.7665,  7.6966, 10.8008, 10.8008,
        10.8008,  4.8644,  9.2336, 10.8008,  4.9838,  5.0705, 10.8008,  9.1819],
       device='cuda:0')
This is the output:  tensor([[9.1016],
        [9.0312],
        [9.0625],
        [9.0938],
        [9.0156],
        [9.0547],
        [9.1016],
        [9.0391],
        [9.0938],
        [9.0625],
        [9.1016],
        [9.0469],
        [9.1016],
        [9.0391],
        [9.0391],
        [9.0156]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  4.3061, 10.8008, 10.8008, 10.8008,  8.8012,  8.5008,  8.4477,
        10.8008, 10.8008,  5.3357,  5.0916,  9.0775,  7.8635, 10.8008,  7.2902],
       device='cuda:0')
This is the output:  tensor([[9.0703],
        [9.0547],
        [9.0547],
        [9.1250],
        [9.0781],
        [9.0547],
        [9.1094],
        [9.0391],
        [9.0547],
        [9.0781],
        [9.0469],
        [9.0547],
        [9.0703],
        [9.0703],
        [9.1172],
        [9.1250]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.2983,  3.0132, 10.8008,  8.7301,  4.5833,  2.0179, 10.8008,  8.6527,
         9.5587,  4.3499, 10.8008,  6.2979,  8.6459, 10.8008,  3.4694,  3.0530],
       device='cuda:0')
This is the output:  tensor([[9.0859],
        [9.0859],
        [9.0391],
        [9.0234],
        [9.0547],
        [9.0312],
        [9.0938],
        [9.0859],
        [8.9922],
        [9.0156],
        [9.0234],
        [9.0391],
        [9.0391],
        [9.0859],
        [9.0859],
        [9.0469]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.1172,  7.6216,  9.4764, 10.4156, 10.8008,  9.5263,  3.2422,  9.4146,
         9.8850,  8.7458, 10.8008,  6.4588,  5.3640,  5.8236,  9.1254,  6.8974],
       device='cuda:0')
This is the output:  tensor([[9.0234],
        [9.0234],
        [9.0234],
        [8.9609],
        [8.9766],
        [8.9609],
        [9.0156],
        [8.9844],
        [9.0234],
        [8.9922],
        [8.9531],
        [8.9531],
        [8.9688],
        [8.9688],
        [9.0234],
        [8.9922]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3783,  7.3194,  5.4878, 10.8008,  9.2493,  5.0042, 10.8008,  9.2412,
         8.3956,  8.8457,  9.3087,  9.0434,  2.6868,  8.6473,  9.4457,  5.9598],
       device='cuda:0')
This is the output:  tensor([[8.9297],
        [8.8672],
        [8.8750],
        [8.9297],
        [8.9062],
        [8.9141],
        [8.8672],
        [8.8828],
        [8.8750],
        [8.8984],
        [8.8828],
        [8.8828],
        [8.8750],
        [8.8672],
        [8.8672],
        [8.8594]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 7.9662, 10.6732, 10.8008,  9.5059, 10.6434,  5.2673,  9.3653,  7.0692,
         9.1210, 10.8008,  5.5699, 10.8008, 10.8008, 10.8008,  7.8266, 10.8008],
       device='cuda:0')
This is the output:  tensor([[8.8047],
        [8.8438],
        [8.8359],
        [8.8672],
        [8.8438],
        [8.8281],
        [8.8203],
        [8.8359],
        [8.8438],
        [8.8672],
        [8.8281],
        [8.8672],
        [8.8750],
        [8.8672],
        [8.8359],
        [8.8516]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 6.1585,  4.5714, 10.0637,  3.7116,  9.5670,  6.1131, 10.8008,  9.2554,
         4.4720,  3.7740,  5.8400, 10.3338,  7.6878, 10.8008,  4.0481,  8.4658],
       device='cuda:0')
This is the output:  tensor([[8.7812],
        [8.7734],
        [8.7812],
        [8.7422],
        [8.7656],
        [8.7891],
        [8.7891],
        [8.7578],
        [8.7422],
        [8.7656],
        [8.7734],
        [8.7656],
        [8.7656],
        [8.7734],
        [8.7422],
        [8.7891]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 4.5735,  5.8157,  6.1896,  3.1579,  9.8237, 10.0487,  9.1644,  6.0948,
        10.0182,  7.9487,  6.0384,  8.8291,  8.0960,  8.5321,  8.7488,  7.5570],
       device='cuda:0')
This is the output:  tensor([[8.6406],
        [8.6406],
        [8.6562],
        [8.6406],
        [8.6406],
        [8.6562],
        [8.6719],
        [8.6406],
        [8.6328],
        [8.6641],
        [8.6328],
        [8.6484],
        [8.6484],
        [8.6484],
        [8.6719],
        [8.6328]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 5.1610,  7.0435, 10.7407,  8.6955, 10.8008, 10.7521,  8.6913,  6.2477,
         9.4179, 10.8008,  9.1332,  6.0374,  3.2356,  9.5294,  9.5176,  6.0799],
       device='cuda:0')
This is the output:  tensor([[8.5078],
        [8.5078],
        [8.5156],
        [8.5156],
        [8.5156],
        [8.5078],
        [8.5234],
        [8.5312],
        [8.5078],
        [8.5312],
        [8.5156],
        [8.5312],
        [8.5156],
        [8.5391],
        [8.5078],
        [8.5234]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.3229,  9.5656,  7.9825, 10.8008, 10.8008,  4.4405,  9.5806,  9.3761,
         9.2971,  7.2419,  9.7631, 10.8008, 10.8008,  7.1150, 10.6173,  4.7376],
       device='cuda:0')
This is the output:  tensor([[8.4375],
        [8.4219],
        [8.4453],
        [8.4453],
        [8.4375],
        [8.4453],
        [8.4453],
        [8.4453],
        [8.4219],
        [8.4453],
        [8.4375],
        [8.4453],
        [8.4531],
        [8.4297],
        [8.4531],
        [8.4453]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 8.6835, 10.7103, 10.8008,  3.8380,  8.9015,  9.8093,  1.5437,  9.5651,
        10.4347,  9.7901,  5.7579, 10.8008,  9.5364,  4.2921,  2.5178,  2.7386],
       device='cuda:0')
This is the output:  tensor([[8.3281],
        [8.3203],
        [8.3203],
        [8.3359],
        [8.3359],
        [8.3203],
        [8.3203],
        [8.3359],
        [8.3359],
        [8.3438],
        [8.3281],
        [8.3203],
        [8.3359],
        [8.3203],
        [8.3359],
        [8.3359]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([ 9.6373,  6.6234,  8.3428,  6.3927,  5.1598, 10.0165, 10.2597, 10.8008,
         6.4486,  2.7156, 10.1548,  9.6851, 10.8008,  8.4995, 10.0481,  2.8911],
       device='cuda:0')
This is the output:  tensor([[8.2031],
        [8.2031],
        [8.1953],
        [8.1953],
        [8.2031],
        [8.1953],
        [8.1953],
        [8.2031],
        [8.2109],
        [8.1953],
        [8.2109],
        [8.1953],
        [8.2031],
        [8.1953],
        [8.1953],
        [8.2031]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  4.5064,  4.1199, 10.8008, 10.8008,  7.4624, 10.8008,  7.4336,
         9.7051,  6.4706,  8.6061, 10.8008,  9.2624, 10.2741, 10.8008,  4.6065],
       device='cuda:0')
This is the output:  tensor([[8.1016],
        [8.1094],
        [8.1016],
        [8.1094],
        [8.1094],
        [8.1094],
        [8.1172],
        [8.1172],
        [8.1094],
        [8.1172],
        [8.1016],
        [8.1328],
        [8.1172],
        [8.1094],
        [8.1406],
        [8.1094]], device='cuda:0', dtype=torch.float16,
       grad_fn=<AddmmBackward0>)
This is the label:  tensor([10.8008,  1.6376,  5.3808,  9.7513, 10.8008, 10.4450,  4.9939, 10.8008,
         4.6932, 10.8008,  5.1883,  9.2675,  8.3977,  5.1310,  8.3599,  9.3509],
       device='cuda:0')
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/train.py", line 263, in <module>
    main()
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/train.py", line 259, in main
    trainer.run()
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/train.py", line 182, in run
    train_loss = self.train_epoch(epoch)
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/train.py", line 120, in train_epoch
    for batch_idx, data in enumerate(tqdm(self.train_loader, desc="Training", leave=False)):
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch_geometric/data/dataset.py", line 291, in __getitem__
    data = self.get(self.indices()[idx])
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/proteinDNADataset.py", line 180, in get
    data = torch.load(os.path.join(self.processed_dir,
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/serialization.py", line 1097, in load
    return _load(
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/serialization.py", line 1525, in _load
    result = unpickler.load()
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/serialization.py", line 1492, in persistent_load
    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/serialization.py", line 1457, in load_tensor
    storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/train.py", line 263, in <module>
    main()
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/train.py", line 259, in main
    trainer.run()
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/train.py", line 182, in run
    train_loss = self.train_epoch(epoch)
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/train.py", line 120, in train_epoch
    for batch_idx, data in enumerate(tqdm(self.train_loader, desc="Training", leave=False)):
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch_geometric/data/dataset.py", line 291, in __getitem__
    data = self.get(self.indices()[idx])
  File "/home/marcus/programming/structural_binding_affinity_predictions_using_gnn/src/proteinDNADataset.py", line 180, in get
    data = torch.load(os.path.join(self.processed_dir,
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/serialization.py", line 1097, in load
    return _load(
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/serialization.py", line 1525, in _load
    result = unpickler.load()
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/serialization.py", line 1492, in persistent_load
    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/home/marcus/programming/gnn-protein-dna/lib/python3.10/site-packages/torch/serialization.py", line 1457, in load_tensor
    storage = zip_file.get_storage_from_record(name, numel, torch.UntypedStorage)._typed_storage()._untyped_storage
KeyboardInterrupt
